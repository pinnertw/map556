{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iffzAWwBELNL",
    "outputId": "07816cb3-31f4-4ed0-8817-09e8c7b8bd5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(seconde, position):\n",
    "    return np.array([-(position[0]-10.*seconde),-(position[1]-(20.*seconde-2*seconde** 2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iffzAWwBELNL",
    "outputId": "07816cb3-31f4-4ed0-8817-09e8c7b8bd5e"
   },
   "outputs": [],
   "source": [
    "class RBuffer():\n",
    "    def __init__(self, maxsize, statedim, naction):\n",
    "        self.cnt = 0\n",
    "        self.maxsize = maxsize\n",
    "        self.state_memory = np.zeros((maxsize, *statedim), dtype=np.float32)\n",
    "        self.action_memory = np.zeros((maxsize, naction), dtype=np.float32)\n",
    "        self.reward_memory = np.zeros((maxsize,), dtype=np.float32)\n",
    "        self.next_state_memory = np.zeros((maxsize, *statedim), dtype=np.float32)\n",
    "        self.done_memory = np.zeros((maxsize,), dtype= np.bool)\n",
    "\n",
    "    def storexp(self, state, next_state, action, done, reward):\n",
    "        index = self.cnt % self.maxsize\n",
    "        self.state_memory[index] = state\n",
    "        self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.next_state_memory[index] = next_state\n",
    "        self.done_memory[index] = 1- int(done)\n",
    "        self.cnt += 1\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        max_mem = min(self.cnt, self.maxsize)\n",
    "        batch = np.random.choice(max_mem, batch_size, replace= False)\n",
    "        states = self.state_memory[batch]\n",
    "        next_states = self.next_state_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        dones = self.done_memory[batch]\n",
    "        return states, next_states, rewards, actions, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iffzAWwBELNL",
    "outputId": "07816cb3-31f4-4ed0-8817-09e8c7b8bd5e"
   },
   "outputs": [],
   "source": [
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.f1 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.f2 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        #self.f3 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        #self.f4 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.v =  tf.keras.layers.Dense(1, activation=None)\n",
    "\n",
    "    def call(self, inputstate, action):\n",
    "        x = self.f1(tf.concat([inputstate, action], axis=1))\n",
    "        x = self.f2(x)\n",
    "        #x = self.f3(x)\n",
    "        #x = self.f4(x)\n",
    "        x = self.v(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iffzAWwBELNL",
    "outputId": "07816cb3-31f4-4ed0-8817-09e8c7b8bd5e"
   },
   "outputs": [],
   "source": [
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self, no_action):\n",
    "        super(Actor, self).__init__()\n",
    "        initializer = tf.keras.initializers.TruncatedNormal(mean=0., stddev=0.2)\n",
    "        self.f1 = tf.keras.layers.Dense(40, kernel_initializer=initializer, activation='relu')\n",
    "        self.f2 = tf.keras.layers.Dense(40, kernel_initializer=initializer, activation='relu')\n",
    "        self.mu =  tf.keras.layers.Dense(no_action, activation=None)\n",
    "\n",
    "    def call(self, state):\n",
    "        x = self.f1(state)\n",
    "        x = self.f2(x)\n",
    "        x = self.mu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iffzAWwBELNL",
    "outputId": "07816cb3-31f4-4ed0-8817-09e8c7b8bd5e"
   },
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, n_action= 2):\n",
    "        self.actor_main = Actor(n_action)\n",
    "        self.actor_target = Actor(n_action)\n",
    "        self.critic_main = Critic()\n",
    "        self.critic_main2 = Critic()\n",
    "        self.critic_target = Critic()\n",
    "        self.critic_target2 = Critic()\n",
    "        self.batch_size = 128\n",
    "        self.n_actions = 2\n",
    "        self.a_opt = tf.keras.optimizers.Adam(0.001)\n",
    "        # self.actor_target = tf.keras.optimizers.Adam(.001)\n",
    "        self.c_opt1 = tf.keras.optimizers.Adam(0.002)\n",
    "        self.c_opt2 = tf.keras.optimizers.Adam(0.002)\n",
    "        # self.critic_target = tf.keras.optimizers.Adam(.002)\n",
    "        self.memory = RBuffer(100000, [3], n_action)\n",
    "        self.trainstep = 0\n",
    "        #self.replace = 5\n",
    "        self.gamma = 0.99\n",
    "        self.min_action = -100\n",
    "        self.max_action = 100\n",
    "        self.actor_update_steps = 20\n",
    "        self.warmup = 200\n",
    "        self.actor_target.compile(optimizer=self.a_opt)\n",
    "        self.critic_target.compile(optimizer=self.c_opt1)\n",
    "        self.critic_target2.compile(optimizer=self.c_opt2)\n",
    "        self.tau = 0.005\n",
    "\n",
    "    def savexp(self,state, next_state, action, done, reward):\n",
    "        self.memory.storexp(state, next_state, action, done, reward)\n",
    "\n",
    "    def update_target(self, tau=None):\n",
    "\n",
    "        if tau is None:\n",
    "            tau = self.tau\n",
    "\n",
    "        weights1 = []\n",
    "        targets1 = self.actor_target.weights\n",
    "        for i, weight in enumerate(self.actor_main.weights):\n",
    "            weights1.append(weight * tau + targets1[i]*(1-tau))\n",
    "        self.actor_target.set_weights(weights1)\n",
    "\n",
    "        weights2 = []\n",
    "        targets2 = self.critic_target.weights\n",
    "        for i, weight in enumerate(self.critic_main.weights):\n",
    "            weights2.append(weight * tau + targets2[i]*(1-tau))\n",
    "        self.critic_target.set_weights(weights2)\n",
    "\n",
    "\n",
    "        weights3 = []\n",
    "        targets3 = self.critic_target2.weights\n",
    "        for i, weight in enumerate(self.critic_main2.weights):\n",
    "            weights3.append(weight * tau + targets3[i]*(1-tau))\n",
    "        self.critic_target2.set_weights(weights3)\n",
    "\n",
    "  \n",
    "    def train(self):\n",
    "        if self.memory.cnt < self.batch_size:\n",
    "            return\n",
    "\n",
    "        states, next_states, rewards, actions, dones = self.memory.sample(self.batch_size)\n",
    "\n",
    "        states = tf.convert_to_tensor(states, dtype= tf.float32)\n",
    "        next_states = tf.convert_to_tensor(next_states, dtype= tf.float32)\n",
    "        rewards = tf.convert_to_tensor(rewards, dtype= tf.float32)\n",
    "        actions = tf.convert_to_tensor(actions, dtype= tf.float32)\n",
    "        #dones = tf.convert_to_tensor(dones, dtype= tf.bool)\n",
    "\n",
    "        with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
    "\n",
    "            target_actions = self.actor_target(next_states)\n",
    "            target_actions += tf.clip_by_value(tf.random.normal(shape=[*np.shape(target_actions)], mean=0.0, stddev=0.2), -0.5, 0.5)\n",
    "            target_actions = tf.clip_by_value(target_actions, self.min_action, self.max_action)\n",
    "\n",
    "\n",
    "            target_next_state_values = tf.squeeze(self.critic_target(next_states, target_actions), 1)\n",
    "            target_next_state_values2 = tf.squeeze(self.critic_target2(next_states, target_actions), 1)\n",
    "\n",
    "            critic_value = tf.squeeze(self.critic_main(states, actions), 1)\n",
    "            critic_value2 = tf.squeeze(self.critic_main2(states, actions), 1)\n",
    "\n",
    "            next_state_target_value = tf.math.minimum(target_next_state_values, target_next_state_values2)\n",
    "\n",
    "            target_values = rewards + self.gamma * next_state_target_value * dones\n",
    "            critic_loss1 = tf.keras.losses.MSE(target_values, critic_value)\n",
    "            critic_loss2 = tf.keras.losses.MSE(target_values, critic_value2)\n",
    "\n",
    "        grads1 = tape1.gradient(critic_loss1, self.critic_main.trainable_variables)\n",
    "        grads2 = tape2.gradient(critic_loss2, self.critic_main2.trainable_variables)\n",
    "\n",
    "        self.c_opt1.apply_gradients(zip(grads1, self.critic_main.trainable_variables))\n",
    "        self.c_opt2.apply_gradients(zip(grads2, self.critic_main2.trainable_variables))\n",
    "\n",
    "\n",
    "        self.trainstep +=1\n",
    "\n",
    "        if self.trainstep % self.actor_update_steps == 0:\n",
    "\n",
    "            with tf.GradientTape() as tape3:\n",
    "\n",
    "                new_policy_actions = self.actor_main(states)\n",
    "                actor_loss = self.critic_main(states, new_policy_actions)\n",
    "                actor_loss = tf.math.reduce_mean(actor_loss)\n",
    "\n",
    "            grads3 = tape3.gradient(actor_loss, self.actor_main.trainable_variables)\n",
    "            self.a_opt.apply_gradients(zip(grads3, self.actor_main.trainable_variables))\n",
    "\n",
    "        #if self.trainstep % self.replace == 0:\n",
    "        self.update_target()\n",
    "\n",
    "    def act(self, state, evaluate=False):\n",
    "        if self.trainstep > self.warmup:\n",
    "            evaluate = True\n",
    "        state = tf.convert_to_tensor([state], dtype=tf.float32)\n",
    "        actions = self.actor_main(state)\n",
    "        if not evaluate:\n",
    "            actions += tf.random.normal(shape=[self.n_actions], mean=0.0, stddev=0.1)\n",
    "        actions = tf.clip_by_value(actions, self.min_action, self.max_action)\n",
    "        return actions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iffzAWwBELNL",
    "outputId": "07816cb3-31f4-4ed0-8817-09e8c7b8bd5e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward after 0 steps is 1796.354822134577 and avg reward is 1796.354822134577\n",
      "total reward after 50 steps is 86.17583132122475 and avg reward is 941.2653267279009\n",
      "total reward after 100 steps is 1300.8097986948412 and avg reward is 1061.1134840502143\n",
      "total reward after 150 steps is 7494.521086758426 and avg reward is 2669.465384727267\n",
      "total reward after 200 steps is 4360.491921577725 and avg reward is 3007.6706920973584\n",
      "total reward after 250 steps is 7448.684128763389 and avg reward is 3747.839598208364\n",
      "total reward after 300 steps is 350.0106812027828 and avg reward is 3262.435467207567\n",
      "total reward after 350 steps is 443.94151622776707 and avg reward is 2910.123723335091\n",
      "total reward after 400 steps is 3347.249207657332 and avg reward is 2958.693221593118\n",
      "total reward after 450 steps is 765.4834687217527 and avg reward is 2739.372246305981\n",
      "total reward after 500 steps is 124.26823440229357 and avg reward is 2501.6355179511006\n",
      "total reward after 550 steps is 11590.894980093151 and avg reward is 3259.073806462938\n",
      "total reward after 600 steps is 2317.7761831444936 and avg reward is 3186.666296976904\n",
      "total reward after 650 steps is 2783.279401883435 and avg reward is 3157.85294732737\n",
      "total reward after 700 steps is 2170.366443291265 and avg reward is 3092.020513724963\n",
      "total reward after 750 steps is 679.4233593393672 and avg reward is 2941.233191575864\n",
      "total reward after 800 steps is 2144.5081384641785 and avg reward is 2894.3670119810595\n",
      "total reward after 850 steps is 3423.9029915196256 and avg reward is 2923.7856775109794\n",
      "total reward after 900 steps is 285.0549868406413 and avg reward is 2784.9051148441195\n",
      "total reward after 950 steps is 6641.734557861364 and avg reward is 2977.746586994982\n",
      "total reward after 1000 steps is 2346.690679737474 and avg reward is 2947.6963056970053\n",
      "total reward after 1050 steps is 5526.505832809797 and avg reward is 3064.9149205657686\n",
      "total reward after 1100 steps is 1416.437857397402 and avg reward is 2993.2420047758396\n",
      "total reward after 1150 steps is 5105.155747861358 and avg reward is 3081.238410737736\n",
      "total reward after 1200 steps is 430.44309954089636 and avg reward is 2975.206598289862\n",
      "total reward after 1250 steps is 817.4015822027665 and avg reward is 2892.214097671128\n",
      "total reward after 1300 steps is 403.4222969375384 and avg reward is 2800.036623569884\n",
      "total reward after 1350 steps is 602.8294727724742 and avg reward is 2721.5649396128333\n",
      "total reward after 1400 steps is 846.3523724049663 and avg reward is 2656.9024372953204\n",
      "total reward after 1450 steps is 305.99964302857535 and avg reward is 2578.539010819762\n",
      "total reward after 1500 steps is 1355.033845020421 and avg reward is 2539.07110224559\n",
      "total reward after 1550 steps is 423.67194183470247 and avg reward is 2472.96487848275\n",
      "total reward after 1600 steps is 466.8327850688779 and avg reward is 2412.172996864148\n",
      "total reward after 1650 steps is 1568.1459638092497 and avg reward is 2387.3486723625333\n",
      "total reward after 1700 steps is 299.408790618156 and avg reward is 2327.6932471698365\n",
      "total reward after 1750 steps is 929.0399686770535 and avg reward is 2288.841767211704\n",
      "total reward after 1800 steps is 219.4223425509175 and avg reward is 2232.911512491142\n",
      "total reward after 1850 steps is 383.5203348283106 and avg reward is 2184.243323605278\n",
      "total reward after 1900 steps is 1546.460944817312 and avg reward is 2167.8899292773813\n",
      "total reward after 1950 steps is 1547.7392384849222 and avg reward is 2152.38616200757\n",
      "total reward after 2000 steps is 684.8189383941645 and avg reward is 2116.5918394804135\n",
      "total reward after 2050 steps is 740.8191578178939 and avg reward is 2083.8353470598777\n",
      "total reward after 2100 steps is 4354.907869888575 and avg reward is 2136.6509871256612\n",
      "total reward after 2150 steps is 707.3763742525231 and avg reward is 2104.167473196726\n",
      "total reward after 2200 steps is 490.3759839270656 and avg reward is 2068.305440101845\n",
      "total reward after 2250 steps is 333.4627351365151 and avg reward is 2030.5914682547723\n",
      "total reward after 2300 steps is 1289.546841617172 and avg reward is 2014.8245613050362\n",
      "total reward after 2350 steps is 798.9458003267785 and avg reward is 1989.4937537846563\n",
      "total reward after 2400 steps is 4107.671517015125 and avg reward is 2032.7218714016046\n",
      "total reward after 2450 steps is 1256.830833422317 and avg reward is 2017.204050642019\n",
      "total reward after 2500 steps is 327.2927862369045 and avg reward is 1984.0685356536833\n",
      "total reward after 2550 steps is 3878.663343661461 and avg reward is 2020.5030511922946\n",
      "total reward after 2600 steps is 532.7554120982107 and avg reward is 1992.432341020708\n",
      "total reward after 2650 steps is 13991.699284243074 and avg reward is 2214.6409881174186\n",
      "total reward after 2700 steps is 3124.832631100692 and avg reward is 2231.1899270807507\n",
      "total reward after 2750 steps is 392.5576855713387 and avg reward is 2198.357208482368\n",
      "total reward after 2800 steps is 3011.4866673341967 and avg reward is 2212.6226375850315\n",
      "total reward after 2850 steps is 1554.7597264032784 and avg reward is 2201.2801735991393\n",
      "total reward after 2900 steps is 3243.807684440325 and avg reward is 2218.950131410007\n",
      "total reward after 2950 steps is 13153.432754033229 and avg reward is 2401.1915084537272\n",
      "total reward after 3000 steps is 855.8283202629331 and avg reward is 2375.857685696501\n",
      "total reward after 3050 steps is 842.210159698911 and avg reward is 2351.121435277185\n",
      "total reward after 3100 steps is 462.8305780078319 and avg reward is 2321.1485645268776\n",
      "total reward after 3150 steps is 839.9012344031289 and avg reward is 2298.0040749936943\n",
      "total reward after 3200 steps is 3953.688295437682 and avg reward is 2323.4761399236017\n",
      "total reward after 3250 steps is 3523.198715383165 and avg reward is 2341.653754703292\n",
      "total reward after 3300 steps is 1713.329966501658 and avg reward is 2332.275787715208\n",
      "total reward after 3350 steps is 1664.7584250291827 and avg reward is 2322.4593559110017\n",
      "total reward after 3400 steps is 2108.605187190756 and avg reward is 2319.360020132447\n",
      "total reward after 3450 steps is 2101.775474558368 and avg reward is 2316.2516694813894\n",
      "total reward after 3500 steps is 1417.922605748379 and avg reward is 2303.5991474569805\n",
      "total reward after 3550 steps is 1669.10435482694 and avg reward is 2294.7867197815635\n",
      "total reward after 3600 steps is 2218.956085755089 and avg reward is 2293.747943972982\n",
      "total reward after 3650 steps is 2209.343810983802 and avg reward is 2292.607347581236\n",
      "total reward after 3700 steps is 8218.155215987772 and avg reward is 2371.614652493323\n",
      "total reward after 3750 steps is 4522.313594131556 and avg reward is 2399.9133227780367\n",
      "total reward after 3800 steps is 1856.4540274040487 and avg reward is 2392.8554098511017\n",
      "total reward after 3850 steps is 1944.145204260229 and avg reward is 2387.1027149076285\n",
      "total reward after 3900 steps is 11698.804381469201 and avg reward is 2504.9723562565096\n",
      "total reward after 3950 steps is 2909.874492560388 and avg reward is 2510.0336329603083\n",
      "total reward after 4000 steps is 2581.6337248841437 and avg reward is 2510.9175847124543\n",
      "total reward after 4050 steps is 7487.7539712064145 and avg reward is 2571.6107113770145\n",
      "total reward after 4100 steps is 8738.814266458021 and avg reward is 2645.9143686671473\n",
      "total reward after 4150 steps is 3099.7599915544756 and avg reward is 2651.317292749139\n",
      "total reward after 4200 steps is 5189.841278629693 and avg reward is 2681.1822808183224\n",
      "total reward after 4250 steps is 2108.363255038917 and avg reward is 2674.5215944720503\n",
      "total reward after 4300 steps is 2701.701697744932 and avg reward is 2674.834009452198\n",
      "total reward after 4350 steps is 7690.837498168893 and avg reward is 2731.834049096706\n",
      "total reward after 4400 steps is 1827.7011289773864 and avg reward is 2721.675252241433\n",
      "total reward after 4450 steps is 2054.2648756389444 and avg reward is 2714.2595813902944\n",
      "total reward after 4500 steps is 4947.676484511426 and avg reward is 2738.8026242817355\n",
      "total reward after 4550 steps is 2278.444441192013 and avg reward is 2733.798730987282\n",
      "total reward after 4600 steps is 1095.8678236747473 and avg reward is 2716.1865706935987\n",
      "total reward after 4650 steps is 3047.3097867764063 and avg reward is 2719.709158098735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward after 4700 steps is 1211.9116347355084 and avg reward is 2703.8376052212275\n",
      "total reward after 4750 steps is 2213.7237265928757 and avg reward is 2698.7322523188486\n",
      "total reward after 4800 steps is 1191.2564630137158 and avg reward is 2683.191264800239\n",
      "total reward after 4850 steps is 2739.3192945461624 and avg reward is 2683.763999797646\n",
      "total reward after 4900 steps is 1165.1966862994589 and avg reward is 2668.4249360249373\n",
      "total reward after 4950 steps is 1299.8142951546363 and avg reward is 2654.7388296162344\n",
      "total reward after 5000 steps is 6155.963556808764 and avg reward is 2698.334916962976\n",
      "total reward after 5050 steps is 1027.4779563766824 and avg reward is 2707.747938213531\n",
      "total reward after 5100 steps is 3481.6608991499334 and avg reward is 2729.556449218082\n",
      "total reward after 5150 steps is 1067.8293680417248 and avg reward is 2665.2895320309144\n",
      "total reward after 5200 steps is 1986.242853607795 and avg reward is 2641.5470413512153\n",
      "total reward after 5250 steps is 1328.77500500115 and avg reward is 2580.3479501135926\n",
      "total reward after 5300 steps is 1653.107201878414 and avg reward is 2593.378915320349\n",
      "total reward after 5350 steps is 1313.2182994484733 and avg reward is 2602.0716831525565\n",
      "total reward after 5400 steps is 1092.0086955210159 and avg reward is 2579.519278031193\n",
      "total reward after 5450 steps is 1811.0156390474842 and avg reward is 2589.9745997344503\n",
      "total reward after 5500 steps is 2039.54223915958 and avg reward is 2609.1273397820232\n",
      "total reward after 5550 steps is 1847.7260282403859 and avg reward is 2511.6956502634957\n",
      "total reward after 5600 steps is 2574.820847360388 and avg reward is 2514.266096905654\n",
      "total reward after 5650 steps is 1631.0245253832986 and avg reward is 2502.7435481406537\n",
      "total reward after 5700 steps is 1091.4957654525972 and avg reward is 2491.9548413622665\n",
      "total reward after 5750 steps is 805.3846093791298 and avg reward is 2493.2144538626644\n",
      "total reward after 5800 steps is 3727.5792925694877 and avg reward is 2509.0451654037174\n",
      "total reward after 5850 steps is 1686.4815002406635 and avg reward is 2491.670950490928\n",
      "total reward after 5900 steps is 3820.3424564940547 and avg reward is 2527.023825187462\n",
      "total reward after 5950 steps is 2198.371544093478 and avg reward is 2482.590195049783\n",
      "total reward after 6000 steps is 851.4847877952853 and avg reward is 2467.638136130361\n",
      "total reward after 6050 steps is 985.1569810782365 and avg reward is 2422.224647613046\n",
      "total reward after 6100 steps is 759.4099473985598 and avg reward is 2415.6543685130573\n",
      "total reward after 6150 steps is 2678.8218141525863 and avg reward is 2391.3910291759694\n",
      "total reward after 6200 steps is 1238.553024848439 and avg reward is 2399.4721284290445\n",
      "total reward after 6250 steps is 995.0791944677928 and avg reward is 2401.248904551695\n",
      "total reward after 6300 steps is 1622.4218295061423 and avg reward is 2413.438899877381\n",
      "total reward after 6350 steps is 1099.853973607546 and avg reward is 2418.4091448857316\n",
      "total reward after 6400 steps is 1323.486234071023 and avg reward is 2423.1804835023927\n",
      "total reward after 6450 steps is 801.2471437031775 and avg reward is 2428.1329585091385\n",
      "total reward after 6500 steps is 2686.8373513258175 and avg reward is 2441.450993572192\n",
      "total reward after 6550 steps is 1204.2701386709034 and avg reward is 2449.256975540554\n",
      "total reward after 6600 steps is 4209.442359683019 and avg reward is 2486.6830712866954\n",
      "total reward after 6650 steps is 2631.1799043007672 and avg reward is 2497.313410691611\n",
      "total reward after 6700 steps is 100.08710104515815 and avg reward is 2495.320193795881\n",
      "total reward after 6750 steps is 341.95410783402326 and avg reward is 2489.4493351874507\n",
      "total reward after 6800 steps is 1704.9576709486666 and avg reward is 2504.304688471428\n",
      "total reward after 6850 steps is 278.98996089791103 and avg reward is 2503.259384732124\n",
      "total reward after 6900 steps is 52.15887612908881 and avg reward is 2488.316364045242\n",
      "total reward after 6950 steps is 224.68744285007537 and avg reward is 2475.0858460888935\n",
      "total reward after 7000 steps is 157.85196575594665 and avg reward is 2469.8161763625117\n",
      "total reward after 7050 steps is 7463.206307806366 and avg reward is 2537.040047862396\n",
      "total reward after 7100 steps is 334.63870279283543 and avg reward is 2496.8373561914386\n",
      "total reward after 7150 steps is 2181.5448670523056 and avg reward is 2511.5790411194366\n",
      "total reward after 7200 steps is 1580.398671655362 and avg reward is 2522.4792679967195\n",
      "total reward after 7250 steps is 290.420056484617 and avg reward is 2522.0488412102004\n",
      "total reward after 7300 steps is 1958.520988779275 and avg reward is 2528.7385826818218\n",
      "total reward after 7350 steps is 262.79667454793116 and avg reward is 2523.377091424033\n",
      "total reward after 7400 steps is 540.5772220809829 and avg reward is 2487.7061484746914\n",
      "total reward after 7450 steps is 974.000876269602 and avg reward is 2484.8778489031647\n",
      "total reward after 7500 steps is 1922.25898130838 and avg reward is 2500.8275108538787\n",
      "total reward after 7550 steps is 544.1546914263515 and avg reward is 2467.482424331528\n",
      "total reward after 7600 steps is 510.72091847400947 and avg reward is 2467.262079395286\n",
      "total reward after 7650 steps is 394.26609112037687 and avg reward is 2331.287747464059\n",
      "total reward after 7700 steps is 1307.5918816813085 and avg reward is 2313.1153399698655\n",
      "total reward after 7750 steps is 740.4050138890345 and avg reward is 2316.5938132530428\n",
      "total reward after 7800 steps is 267.7104175033558 and avg reward is 2289.156050754734\n",
      "total reward after 7850 steps is 2901.454323797995 and avg reward is 2302.622996728681\n",
      "total reward after 7900 steps is 113.08780927632054 and avg reward is 2271.3157979770413\n",
      "total reward after 7950 steps is 380.92362344822544 and avg reward is 2143.5907066711907\n",
      "total reward after 8000 steps is 6407.541500650908 and avg reward is 2199.107838475071\n",
      "total reward after 8050 steps is 1206.4393436910839 and avg reward is 2202.7501303149925\n",
      "total reward after 8100 steps is 494.1517213312245 and avg reward is 2203.063341748227\n",
      "total reward after 8150 steps is 853.0259435354949 and avg reward is 2203.1945888395503\n",
      "total reward after 8200 steps is 121.89738257054753 and avg reward is 2164.8766797108783\n",
      "total reward after 8250 steps is 181.99501674030498 and avg reward is 2131.46464272445\n",
      "total reward after 8300 steps is 276.63874725623543 and avg reward is 2117.097730531996\n",
      "total reward after 8350 steps is 1267.727258924729 and avg reward is 2113.1274188709517\n",
      "total reward after 8400 steps is 497.45427802757223 and avg reward is 2097.0159097793194\n",
      "total reward after 8450 steps is 4814.388390641205 and avg reward is 2124.142038940148\n",
      "total reward after 8500 steps is 3423.026131997152 and avg reward is 2144.193074202635\n",
      "total reward after 8550 steps is 1290.000363463302 and avg reward is 2140.4020342889994\n",
      "total reward after 8600 steps is 4600.616471379103 and avg reward is 2164.2186381452393\n",
      "total reward after 8650 steps is 1710.7304598296944 and avg reward is 2159.232504633698\n",
      "total reward after 8700 steps is 372.64462231929144 and avg reward is 2080.7773986970137\n",
      "total reward after 8750 steps is 159.7970243342274 and avg reward is 2037.1522329990403\n",
      "total reward after 8800 steps is 1290.812722932257 and avg reward is 2031.4958199543223\n",
      "total reward after 8850 steps is 1072.2535532000222 and avg reward is 2022.7769034437201\n",
      "total reward after 8900 steps is 4049.6731302732956 and avg reward is 1946.285590931761\n",
      "total reward after 8950 steps is 3023.930592780766 and avg reward is 1947.4261519339648\n",
      "total reward after 9000 steps is 2006.1316105701242 and avg reward is 1941.6711307908245\n",
      "total reward after 9050 steps is 195.75506332024526 and avg reward is 1868.751141711963\n",
      "total reward after 9100 steps is 4092.4905545446773 and avg reward is 1822.2879045928296\n",
      "total reward after 9150 steps is 212.26673681248508 and avg reward is 1793.4129720454096\n",
      "total reward after 9200 steps is 5784.354690277719 and avg reward is 1799.3581061618895\n",
      "total reward after 9250 steps is 2511.4090063058443 and avg reward is 1803.388563674559\n",
      "total reward after 9300 steps is 127.13120497075978 and avg reward is 1777.6428587468174\n",
      "total reward after 9350 steps is 178.70421123369022 and avg reward is 1702.5215258774654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward after 9400 steps is 2200.6974273159444 and avg reward is 1706.2514888608512\n",
      "total reward after 9450 steps is 735.0021912503853 and avg reward is 1693.0588620169656\n",
      "total reward after 9500 steps is 7856.854493986842 and avg reward is 1722.1506421117197\n",
      "total reward after 9550 steps is 124.51764106923102 and avg reward is 1700.6113741104919\n",
      "total reward after 9600 steps is 5172.268690230819 and avg reward is 1741.3753827760522\n",
      "total reward after 9650 steps is 953.3635828511551 and avg reward is 1720.4359207368\n",
      "total reward after 9700 steps is 1266.3674339562633 and avg reward is 1720.9804787290077\n",
      "total reward after 9750 steps is 13735.082811229997 and avg reward is 1836.194069575379\n",
      "total reward after 9800 steps is 5568.083932473171 and avg reward is 1879.9623442699738\n",
      "total reward after 9850 steps is 488.67646642683803 and avg reward is 1857.4559159887804\n",
      "total reward after 9900 steps is 1618.3542268850397 and avg reward is 1861.9874913946362\n",
      "total reward after 9950 steps is 10473.745055855423 and avg reward is 1953.726799001644\n",
      "total reward after 10000 steps is 1189.1131325278718 and avg reward is 1904.0582947588348\n",
      "total reward after 10050 steps is 592.6695560638243 and avg reward is 1899.7102107557066\n",
      "total reward after 10100 steps is 621.3786875632271 and avg reward is 1871.1073886398394\n",
      "total reward after 10150 steps is 431.05835072545096 and avg reward is 1864.7396784666767\n",
      "total reward after 10200 steps is 1781.4249452544364 and avg reward is 1862.6914993831429\n",
      "total reward after 10250 steps is 2052.5267165295527 and avg reward is 1869.929016498427\n",
      "total reward after 10300 steps is 247.2403544945032 and avg reward is 1855.8703480245877\n",
      "total reward after 10350 steps is 199.68226882095604 and avg reward is 1844.7349877183128\n",
      "total reward after 10400 steps is 1734.0141396702936 and avg reward is 1851.1550421598054\n",
      "total reward after 10450 steps is 525.0852998364221 and avg reward is 1838.295738767695\n",
      "total reward after 10500 steps is 2488.1478632028156 and avg reward is 1842.781795008127\n",
      "total reward after 10550 steps is 1270.6004528966 and avg reward is 1837.0105392546889\n",
      "total reward after 10600 steps is 1143.0995290022909 and avg reward is 1822.6933260711078\n",
      "total reward after 10650 steps is 11995.907604015054 and avg reward is 1926.3421568574256\n",
      "total reward after 10700 steps is 238.57154716048268 and avg reward is 1917.8129146745043\n",
      "total reward after 10750 steps is 726.2373995008896 and avg reward is 1917.0214425757224\n",
      "total reward after 10800 steps is 1102.333341408455 and avg reward is 1890.768983064112\n",
      "total reward after 10850 steps is 1791.5920216874972 and avg reward is 1891.8200882785804\n",
      "total reward after 10900 steps is 993.732687233609 and avg reward is 1863.5539905859757\n",
      "total reward after 10950 steps is 830.202497162508 and avg reward is 1849.8723001166663\n",
      "total reward after 11000 steps is 893.3337302216901 and avg reward is 1850.2907895409305\n",
      "total reward after 11050 steps is 817.0525956052188 and avg reward is 1848.6097456862\n",
      "total reward after 11100 steps is 852.2416614574246 and avg reward is 1849.5380628267887\n",
      "total reward after 11150 steps is 1860.0801066895856 and avg reward is 1841.350645752159\n",
      "total reward after 11200 steps is 1326.4959071680503 and avg reward is 1842.230074575355\n",
      "total reward after 11250 steps is 1501.3295128716672 and avg reward is 1847.2925777593937\n",
      "total reward after 11300 steps is 4839.796483822508 and avg reward is 1879.466324302557\n",
      "total reward after 11350 steps is 1736.6031866474477 and avg reward is 1885.8338164329562\n",
      "total reward after 11400 steps is 4632.684613803435 and avg reward is 1918.9258002302802\n",
      "total reward after 11450 steps is 6706.24115639255 and avg reward is 1977.9757403571741\n",
      "total reward after 11500 steps is 943.7258343129589 and avg reward is 1960.5446251870453\n",
      "total reward after 11550 steps is 3752.086284703853 and avg reward is 1986.0227866473751\n",
      "total reward after 11600 steps is 1812.8635591992274 and avg reward is 1962.056998642537\n",
      "total reward after 11650 steps is 1285.6455410190072 and avg reward is 1948.6016550097195\n",
      "total reward after 11700 steps is 1337.022607648634 and avg reward is 1960.9710100757545\n",
      "total reward after 11750 steps is 1385.971566843239 and avg reward is 1971.4111846658461\n",
      "total reward after 11800 steps is 656.6024035995816 and avg reward is 1960.9276319923554\n",
      "total reward after 11850 steps is 7755.124958441992 and avg reward is 2035.6889819677963\n",
      "total reward after 11900 steps is 4268.188416206546 and avg reward is 2077.8492773685707\n",
      "total reward after 11950 steps is 3127.725487291275 and avg reward is 2106.879657812983\n",
      "total reward after 12000 steps is 1518.6867911933907 and avg reward is 2120.488006067357\n",
      "total reward after 12050 steps is 1358.572937088399 and avg reward is 2059.4416723601776\n",
      "total reward after 12100 steps is 2597.438868113587 and avg reward is 2082.069674013385\n",
      "total reward after 12150 steps is 702.6498142617868 and avg reward is 2067.28072348548\n",
      "total reward after 12200 steps is 524.0447891754578 and avg reward is 2056.717184660681\n",
      "total reward after 12250 steps is 1383.3446129613906 and avg reward is 2067.6464302254485\n",
      "total reward after 12300 steps is 438.9302486910655 and avg reward is 2052.4505228245666\n",
      "total reward after 12350 steps is 6865.198944470241 and avg reward is 2118.4745455237894\n",
      "total reward after 12400 steps is 104.02186483138101 and avg reward is 2114.108991951294\n",
      "total reward after 12450 steps is 1743.3546113004707 and avg reward is 2121.8025293016026\n",
      "total reward after 12500 steps is 6492.098131628667 and avg reward is 2167.5009208048054\n",
      "total reward after 12550 steps is 76.49150960881374 and avg reward is 2162.82428898663\n",
      "total reward after 12600 steps is 201.77056035815815 and avg reward is 2159.7347854054715\n",
      "total reward after 12650 steps is 120.85605069229413 and avg reward is 2157.0006850011905\n",
      "total reward after 12700 steps is 181.62491034790656 and avg reward is 2145.7410152878565\n",
      "total reward after 12750 steps is 219.74059178644114 and avg reward is 2140.5343710668308\n",
      "total reward after 12800 steps is 672.8905489257282 and avg reward is 2144.586172381054\n",
      "total reward after 12850 steps is 104.48594540347764 and avg reward is 2116.6164885971098\n",
      "total reward after 12900 steps is 205.22570169646684 and avg reward is 2117.537867521311\n",
      "total reward after 12950 steps is 2069.6548264907847 and avg reward is 2134.4251795517366\n",
      "total reward after 13000 steps is 140.16985374459986 and avg reward is 2071.751463082673\n",
      "total reward after 13050 steps is 503.6025487423768 and avg reward is 2064.7230951331862\n",
      "total reward after 13100 steps is 334.5328473980765 and avg reward is 2063.1269063938544\n",
      "total reward after 13150 steps is 119.81173103552696 and avg reward is 2055.7947642688546\n",
      "total reward after 13200 steps is 56.11004795043169 and avg reward is 2055.1368909226535\n",
      "total reward after 13250 steps is 869.9392859736979 and avg reward is 2062.0163336149876\n",
      "total reward after 13300 steps is 67.43633905273916 and avg reward is 2059.9243095329525\n",
      "total reward after 13350 steps is 138.62228526809326 and avg reward is 2048.633259796386\n",
      "total reward after 13400 steps is 169.25063477911482 and avg reward is 2045.3512233639017\n",
      "total reward after 13450 steps is 3632.504325280476 and avg reward is 2033.5323827102943\n",
      "total reward after 13500 steps is 55.93310604945299 and avg reward is 1999.8614524508178\n",
      "total reward after 13550 steps is 415.0310402765788 and avg reward is 1991.1117592189505\n",
      "total reward after 13600 steps is 614.6912818109229 and avg reward is 1951.2525073232684\n",
      "total reward after 13650 steps is 970.6848799397669 and avg reward is 1943.8520515243692\n",
      "total reward after 13700 steps is 311.3373395591102 and avg reward is 1943.2389786967674\n",
      "total reward after 13750 steps is 402.80177151065664 and avg reward is 1945.6690261685317\n",
      "total reward after 13800 steps is 524.5650219715104 and avg reward is 1938.006549158924\n",
      "total reward after 13850 steps is 776.8094444930947 and avg reward is 1935.0521080718545\n",
      "total reward after 13900 steps is 548.421342703161 and avg reward is 1900.039590196153\n",
      "total reward after 13950 steps is 267.0680576696653 and avg reward is 1872.4709648450423\n",
      "total reward after 14000 steps is 865.1088803171552 and avg reward is 1861.060737542513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward after 14050 steps is 104.0277440850333 and avg reward is 1860.1434643501607\n",
      "total reward after 14100 steps is 412.6979851187088 and avg reward is 1823.3455386559012\n",
      "total reward after 14150 steps is 712.7898372745296 and avg reward is 1828.3507696605216\n",
      "total reward after 14200 steps is 1076.9958978848356 and avg reward is 1781.2771817365926\n",
      "total reward after 14250 steps is 363.2687235777553 and avg reward is 1759.7957789093118\n",
      "total reward after 14300 steps is 304.10880061754267 and avg reward is 1761.5655548657794\n",
      "total reward after 14350 steps is 1861.495015299723 and avg reward is 1778.39346290644\n",
      "total reward after 14400 steps is 237.80602383969966 and avg reward is 1758.7645488716773\n",
      "total reward after 14450 steps is 253.1556111062878 and avg reward is 1753.9460830702365\n",
      "total reward after 14500 steps is 135.6901184104894 and avg reward is 1676.7344393144729\n",
      "total reward after 14550 steps is 99.7665894793129 and avg reward is 1676.4869287985734\n",
      "total reward after 14600 steps is 221.0991222907724 and avg reward is 1626.9752331191733\n",
      "total reward after 14650 steps is 232.33483647663536 and avg reward is 1619.764945655428\n",
      "total reward after 14700 steps is 4897.979627160382 and avg reward is 1656.0810675874693\n",
      "total reward after 14750 steps is 1231.3939249235966 and avg reward is 1531.0441787244051\n",
      "total reward after 14800 steps is 369.40611208434274 and avg reward is 1479.057400520517\n",
      "total reward after 14850 steps is 1044.5517750571548 and avg reward is 1484.6161536068203\n",
      "total reward after 14900 steps is 399.44458676456804 and avg reward is 1472.4270572056153\n",
      "total reward after 14950 steps is 941.4656316344973 and avg reward is 1377.1042629634062\n",
      "total reward after 15000 steps is 434.7261452806798 and avg reward is 1369.560393090934\n",
      "total reward after 15050 steps is 357.2428212723334 and avg reward is 1367.2061257430191\n",
      "total reward after 15100 steps is 2427.4093752431513 and avg reward is 1385.2664326198187\n",
      "total reward after 15150 steps is 1579.3977864956382 and avg reward is 1396.7498269775203\n",
      "total reward after 15200 steps is 443.9166446706322 and avg reward is 1383.3747439716824\n",
      "total reward after 15250 steps is 362.59439858695094 and avg reward is 1366.4754207922563\n",
      "total reward after 15300 steps is 268.3448359868044 and avg reward is 1366.6864656071793\n",
      "total reward after 15350 steps is 1237.7097071983567 and avg reward is 1377.066739990953\n",
      "total reward after 15400 steps is 1531.4573946518854 and avg reward is 1375.0411725407691\n",
      "total reward after 15450 steps is 213.53016711665202 and avg reward is 1371.9256212135713\n",
      "total reward after 15500 steps is 738.848994697595 and avg reward is 1354.4326325285192\n",
      "total reward after 15550 steps is 933.321040328136 and avg reward is 1351.0598384028347\n",
      "total reward after 15600 steps is 275.6933333812376 and avg reward is 1342.3857764466238\n",
      "total reward after 15650 steps is 2383.2878294703414 and avg reward is 1246.2595787011771\n",
      "total reward after 15700 steps is 900.4912073935052 and avg reward is 1252.8787753035074\n",
      "total reward after 15750 steps is 206.15161324758918 and avg reward is 1247.6779174409744\n",
      "total reward after 15800 steps is 939.594973554251 and avg reward is 1246.0505337624325\n",
      "total reward after 15850 steps is 248.63659893360227 and avg reward is 1230.6209795348934\n",
      "total reward after 15900 steps is 579.0603242474991 and avg reward is 1226.4742559050324\n",
      "total reward after 15950 steps is 431.28145768326374 and avg reward is 1222.4850455102398\n",
      "total reward after 16000 steps is 250.92426092752117 and avg reward is 1216.0609508172984\n",
      "total reward after 16050 steps is 1764.3866670885102 and avg reward is 1225.534291532131\n",
      "total reward after 16100 steps is 752.3641150350372 and avg reward is 1224.535516067907\n",
      "total reward after 16150 steps is 591.8872553203361 and avg reward is 1211.8535875542145\n",
      "total reward after 16200 steps is 402.77571842420343 and avg reward is 1202.6163856667763\n",
      "total reward after 16250 steps is 58.11894162416654 and avg reward is 1188.1842799543012\n",
      "total reward after 16300 steps is 425.45495161389647 and avg reward is 1144.040864632215\n",
      "total reward after 16350 steps is 137.0228609469405 and avg reward is 1128.04506137521\n",
      "total reward after 16400 steps is 182.41224630948727 and avg reward is 1083.5423377002705\n",
      "total reward after 16450 steps is 992.9948859421988 and avg reward is 1026.409874995767\n",
      "total reward after 16500 steps is 265.1505301477132 and avg reward is 1019.6241219541143\n",
      "total reward after 16550 steps is 400.30392279402247 and avg reward is 986.1062983350162\n",
      "total reward after 16600 steps is 429.4889289677269 and avg reward is 972.2725520327012\n",
      "total reward after 16650 steps is 4068.8919255588207 and avg reward is 1000.1050158780994\n",
      "total reward after 16700 steps is 435.87393896125474 and avg reward is 991.0935291912257\n",
      "total reward after 16750 steps is 78.65152727447595 and avg reward is 978.020328795538\n",
      "total reward after 16800 steps is 2203.610261029315 and avg reward is 993.4904073698355\n",
      "total reward after 16850 steps is 106.45151178747398 and avg reward is 917.0036729032902\n",
      "total reward after 16900 steps is 192.08985603908405 and avg reward is 876.2426873016153\n",
      "total reward after 16950 steps is 124.3081144368534 and avg reward is 846.2085135730711\n",
      "total reward after 17000 steps is 233.5128129366579 and avg reward is 833.3567737905038\n",
      "total reward after 17050 steps is 1204.8250710270158 and avg reward is 831.8192951298901\n",
      "total reward after 17100 steps is 261.8433878315608 and avg reward is 808.4633403270699\n",
      "total reward after 17150 steps is 120.13145727331451 and avg reward is 802.638156757185\n",
      "total reward after 17200 steps is 794.6965546485869 and avg reward is 805.3446744119165\n",
      "total reward after 17250 steps is 2811.4481615908676 and avg reward is 819.6257098982111\n",
      "total reward after 17300 steps is 165.56515627307562 and avg reward is 816.8920589740314\n",
      "total reward after 17350 steps is 987.1978818744076 and avg reward is 758.112048348073\n",
      "total reward after 17400 steps is 833.4508610868372 and avg reward is 765.4063383106275\n",
      "total reward after 17450 steps is 831.1135978727483 and avg reward is 756.2839281763504\n",
      "total reward after 17500 steps is 872.5647687760434 and avg reward is 700.0885945478242\n",
      "total reward after 17550 steps is 139.56657962763245 and avg reward is 700.7193452480122\n",
      "total reward after 17600 steps is 1613.7746136014105 and avg reward is 714.8393857804449\n",
      "total reward after 17650 steps is 230.9929136470691 and avg reward is 715.9407544099927\n",
      "total reward after 17700 steps is 811.5366975291388 and avg reward is 722.239872281805\n",
      "total reward after 17750 steps is 620.3842352336551 and avg reward is 726.246308716277\n",
      "total reward after 17800 steps is 331.33816559329546 and avg reward is 722.8307848829526\n",
      "total reward after 17850 steps is 1491.5903515533055 and avg reward is 736.7018289444507\n",
      "total reward after 17900 steps is 328.4253036301746 and avg reward is 737.933824963788\n",
      "total reward after 17950 steps is 287.28495880943944 and avg reward is 720.1101262869744\n",
      "total reward after 18000 steps is 1492.3952634942127 and avg reward is 733.6323803844706\n",
      "total reward after 18050 steps is 218.124307467604 and avg reward is 730.7775979717229\n",
      "total reward after 18100 steps is 246.045455686641 and avg reward is 729.8927240546086\n",
      "total reward after 18150 steps is 452.097463920405 and avg reward is 733.2155813834573\n",
      "total reward after 18200 steps is 98.1142224137471 and avg reward is 733.6356231280905\n",
      "total reward after 18250 steps is 196.2936582119434 and avg reward is 726.899166850473\n",
      "total reward after 18300 steps is 89.91832616808377 and avg reward is 727.1239867216265\n",
      "total reward after 18350 steps is 129.91267473051118 and avg reward is 727.0368906162506\n",
      "total reward after 18400 steps is 765.3176794414663 and avg reward is 732.9975610628742\n",
      "total reward after 18450 steps is 98.05162837383115 and avg reward is 697.6530340938075\n",
      "total reward after 18500 steps is 218.71422348010668 and avg reward is 699.2808452681139\n",
      "total reward after 18550 steps is 1668.2558499090753 and avg reward is 711.8130933644389\n",
      "total reward after 18600 steps is 233.5694520379493 and avg reward is 708.0018750667093\n",
      "total reward after 18650 steps is 338.41621172351694 and avg reward is 701.6791883845468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward after 18700 steps is 7786.684871683115 and avg reward is 776.432663705787\n",
      "total reward after 18750 steps is 86.7123197704136 and avg reward is 773.2717691883845\n",
      "total reward after 18800 steps is 488.5170480263465 and avg reward is 772.9112894489328\n",
      "total reward after 18850 steps is 1072.6023055283185 and avg reward is 775.8692180592852\n",
      "total reward after 18900 steps is 552.509827060284 and avg reward is 775.9101029028566\n",
      "total reward after 18950 steps is 183.57912706904594 and avg reward is 775.0752135968502\n",
      "total reward after 19000 steps is 483.43483641771695 and avg reward is 771.2584731578557\n",
      "total reward after 19050 steps is 1242.3934699290346 and avg reward is 782.6421304162958\n",
      "total reward after 19100 steps is 226.54801489817544 and avg reward is 780.7806307140904\n",
      "total reward after 19150 steps is 2341.685183119394 and avg reward is 797.0695841725391\n",
      "total reward after 19200 steps is 521.1907994310666 and avg reward is 791.5115331880015\n",
      "total reward after 19250 steps is 115.67264743475707 and avg reward is 789.0355724265713\n",
      "total reward after 19300 steps is 1286.5139887789467 and avg reward is 798.8596243081853\n",
      "total reward after 19350 steps is 3598.250848884375 and avg reward is 816.2271826440318\n",
      "total reward after 19400 steps is 3214.4339768075934 and avg reward is 845.9934621737109\n",
      "total reward after 19450 steps is 1981.8948599632913 and avg reward is 863.2808546622807\n",
      "total reward after 19500 steps is 182.68400148382472 and avg reward is 863.7507934930142\n",
      "total reward after 19550 steps is 608.1414104011964 and avg reward is 868.834541702233\n",
      "total reward after 19600 steps is 3267.1937441445803 and avg reward is 899.2954879207712\n",
      "total reward after 19650 steps is 2733.496996128443 and avg reward is 924.3071095172892\n",
      "total reward after 19700 steps is 119.75022846500616 and avg reward is 876.5248155303354\n",
      "total reward after 19750 steps is 3387.8547954331175 and avg reward is 898.0894242354308\n",
      "total reward after 19800 steps is 561.740713870981 and avg reward is 900.0127702532972\n",
      "total reward after 19850 steps is 1625.3258735080897 and avg reward is 905.8205112378066\n",
      "total reward after 19900 steps is 2322.99310631729 and avg reward is 925.0559964333337\n",
      "total reward after 19950 steps is 1027.7830881290918 and avg reward is 925.9191709982797\n",
      "total reward after 20000 steps is 1469.1403298838845 and avg reward is 936.2633128443116\n",
      "total reward after 20050 steps is 2005.212244401265 and avg reward is 952.7430070756009\n",
      "total reward after 20100 steps is 2290.6113680593776 and avg reward is 951.3750270037632\n",
      "total reward after 20150 steps is 1403.114914702918 and avg reward is 949.6121982858363\n",
      "total reward after 20200 steps is 722.5970365163198 and avg reward is 952.3990022042931\n",
      "total reward after 20250 steps is 1325.113841976519 and avg reward is 962.0241966381889\n",
      "total reward after 20300 steps is 1286.313341662971 and avg reward is 972.2038816949504\n",
      "total reward after 20350 steps is 1898.8655970954974 and avg reward is 978.8154405939218\n",
      "total reward after 20400 steps is 648.6422181208012 and avg reward is 969.9872888286111\n",
      "total reward after 20450 steps is 2150.588222257921 and avg reward is 989.3578693800238\n",
      "total reward after 20500 steps is 594.3135434607032 and avg reward is 987.9125148676549\n",
      "total reward after 20550 steps is 1108.5826563388903 and avg reward is 989.6651310277623\n",
      "total reward after 20600 steps is 2372.1573110949275 and avg reward is 1010.6297708048992\n",
      "total reward after 20650 steps is 1109.6167301485132 and avg reward is 997.8930598116808\n",
      "total reward after 20700 steps is 1512.117380074614 and avg reward is 1004.0093215384918\n",
      "total reward after 20750 steps is 2347.8355240193628 and avg reward is 1025.4261606462098\n",
      "total reward after 20800 steps is 339.6192868198846 and avg reward is 1019.4264037788661\n",
      "total reward after 20850 steps is 971.1958742467532 and avg reward is 1026.6519965319976\n",
      "total reward after 20900 steps is 337.6031264084745 and avg reward is 1024.2374245536075\n",
      "total reward after 20950 steps is 451.89013786426926 and avg reward is 1024.4435113554175\n",
      "total reward after 21000 steps is 637.6841801533405 and avg reward is 1028.3111105476755\n",
      "total reward after 21050 steps is 1236.4005986821464 and avg reward is 1023.0312498636118\n",
      "total reward after 21100 steps is 1101.9072083758754 and avg reward is 1026.5266807970204\n",
      "total reward after 21150 steps is 1937.6260095036025 and avg reward is 1039.984068338853\n",
      "total reward after 21200 steps is 554.9658575289747 and avg reward is 1041.505969729901\n",
      "total reward after 21250 steps is 243.50430453079218 and avg reward is 1043.359823358967\n",
      "total reward after 21300 steps is 2442.1167126543096 and avg reward is 1063.5264409693714\n",
      "total reward after 21350 steps is 2011.7374843775272 and avg reward is 1082.2735872036772\n",
      "total reward after 21400 steps is 320.4352095770892 and avg reward is 1083.6538168363531\n",
      "total reward after 21450 steps is 523.9188127018001 and avg reward is 1078.9630561039492\n",
      "total reward after 21500 steps is 1297.3499658457943 and avg reward is 1089.2850504609298\n",
      "total reward after 21550 steps is 1528.9894919807225 and avg reward is 1100.5719061527968\n",
      "total reward after 21600 steps is 554.9030600239657 and avg reward is 1101.8260474633591\n",
      "total reward after 21650 steps is 377.3977033900501 and avg reward is 1064.9111052416713\n",
      "total reward after 21700 steps is 1105.248797260826 and avg reward is 1071.604853824667\n",
      "total reward after 21750 steps is 527.3094008483195 and avg reward is 1076.0914325604053\n",
      "total reward after 21800 steps is 175.1427822035527 and avg reward is 1055.8067577721479\n",
      "total reward after 21850 steps is 220.2457584917193 and avg reward is 1056.9447002391903\n",
      "total reward after 21900 steps is 182.8040903922028 and avg reward is 1056.8518425827215\n",
      "total reward after 21950 steps is 1311.4267129353293 and avg reward is 1068.7230285677063\n",
      "total reward after 22000 steps is 1683.946285799569 and avg reward is 1083.2273632963354\n",
      "total reward after 22050 steps is 570.4374390595441 and avg reward is 1076.8834869766608\n",
      "total reward after 22100 steps is 220.6327929684424 and avg reward is 1076.4713810280296\n",
      "total reward after 22150 steps is 2334.0836491599857 and avg reward is 1098.6109029468964\n",
      "total reward after 22200 steps is 66.79837046540196 and avg reward is 1091.3319211050648\n",
      "total reward after 22250 steps is 49.949209094334385 and avg reward is 1063.7169315800993\n",
      "total reward after 22300 steps is 620.2591887149918 and avg reward is 1068.2638719045185\n",
      "total reward after 22350 steps is 345.5441232515958 and avg reward is 1061.8473343182902\n",
      "total reward after 22400 steps is 50.388394648567015 and avg reward is 1054.0167096539076\n",
      "total reward after 22450 steps is 117.62233913907072 and avg reward is 1046.8817970665707\n",
      "total reward after 22500 steps is 61.285681785025176 and avg reward is 1038.7690061966607\n",
      "total reward after 22550 steps is 252.46408005702293 and avg reward is 1039.8979812009543\n",
      "total reward after 22600 steps is 302.9438110766022 and avg reward is 1026.7896731757062\n",
      "total reward after 22650 steps is 47.059462396113204 and avg reward is 1024.9503386631966\n",
      "total reward after 22700 steps is 114.05726574465629 and avg reward is 1017.9755443453519\n",
      "total reward after 22750 steps is 421.24155679242597 and avg reward is 1015.9841175609396\n",
      "total reward after 22800 steps is 56.078856931151904 and avg reward is 1013.2315244743182\n",
      "total reward after 22850 steps is 226.03268792387632 and avg reward is 1000.575947838024\n",
      "total reward after 22900 steps is 333.95776380217166 and avg reward is 1000.631272439744\n",
      "total reward after 22950 steps is 545.9039129232667 and avg reward is 1003.2174619808823\n",
      "total reward after 23000 steps is 299.38737149692616 and avg reward is 991.2873830609092\n",
      "total reward after 23050 steps is 183.3178452863427 and avg reward is 990.9393184390965\n",
      "total reward after 23100 steps is 291.4232211196125 and avg reward is 991.3930960934263\n",
      "total reward after 23150 steps is 74.94908713932915 and avg reward is 987.6216123256154\n",
      "total reward after 23200 steps is 287.32845437852507 and avg reward is 989.5137546452632\n",
      "total reward after 23250 steps is 423.28567058496884 and avg reward is 991.7836747689937\n",
      "total reward after 23300 steps is 980.4946038090711 and avg reward is 1000.6894375454036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward after 23350 steps is 182.22402267639364 and avg reward is 1001.2125510248624\n",
      "total reward after 23400 steps is 147.27194672598455 and avg reward is 995.0320936977076\n",
      "total reward after 23450 steps is 253.00451993810003 and avg reward is 996.5816226133503\n",
      "total reward after 23500 steps is 357.0031778603422 and avg reward is 997.9645121571526\n",
      "total reward after 23550 steps is 719.4733968206156 and avg reward is 988.4766876262679\n",
      "total reward after 23600 steps is 279.51352641797894 and avg reward is 988.9361283700683\n",
      "total reward after 23650 steps is 632.0539438864475 and avg reward is 991.8725056916977\n",
      "total reward after 23700 steps is 221.84412776100675 and avg reward is 916.2240982524766\n",
      "total reward after 23750 steps is 293.4848699780142 and avg reward is 918.2918237545526\n",
      "total reward after 23800 steps is 321.4895066989935 and avg reward is 916.6215483412791\n",
      "total reward after 23850 steps is 413.2246254162346 and avg reward is 910.0277715401583\n",
      "total reward after 23900 steps is 438.80366989267645 and avg reward is 908.8907099684819\n",
      "total reward after 23950 steps is 1826.5834175404204 and avg reward is 925.3207528731957\n",
      "total reward after 24000 steps is 315.0022932973316 and avg reward is 923.6364274419918\n",
      "total reward after 24050 steps is 606.3978720189117 and avg reward is 917.2764714628908\n",
      "total reward after 24100 steps is 1243.759032677835 and avg reward is 927.4485816406873\n",
      "total reward after 24150 steps is 263.6534110954608 and avg reward is 906.6682639204482\n",
      "total reward after 24200 steps is 150.87241569467233 and avg reward is 902.965080083084\n",
      "total reward after 24250 steps is 542.7015755178077 and avg reward is 907.2353693639145\n",
      "total reward after 24300 steps is 794.9189376945009 and avg reward is 902.3194188530701\n",
      "total reward after 24350 steps is 776.1216126970307 and avg reward is 874.0981264911966\n",
      "total reward after 24400 steps is 941.1616101450772 and avg reward is 851.3654028245713\n",
      "total reward after 24450 steps is 569.0187449509527 and avg reward is 837.236641674448\n",
      "total reward after 24500 steps is 464.0408409204088 and avg reward is 840.0502100688137\n",
      "total reward after 24550 steps is 183.0900030578224 and avg reward is 835.7996959953801\n",
      "total reward after 24600 steps is 182.43174609257738 and avg reward is 804.95207601486\n",
      "total reward after 24650 steps is 84.36807037745973 and avg reward is 778.4607867573503\n",
      "total reward after 24700 steps is 386.10180915803625 and avg reward is 781.1243025642807\n",
      "total reward after 24750 steps is 1051.6147483715665 and avg reward is 757.7619020936651\n",
      "total reward after 24800 steps is 241.2671876095013 and avg reward is 754.5571668310503\n",
      "total reward after 24850 steps is 1672.3600915693235 and avg reward is 755.0275090116625\n",
      "total reward after 24900 steps is 351.2404754835039 and avg reward is 735.3099827033246\n",
      "total reward after 24950 steps is 223.22977765422277 and avg reward is 727.264449598576\n",
      "total reward after 25000 steps is 748.8228094381645 and avg reward is 720.0612743941188\n",
      "total reward after 25050 steps is 398.81946894659507 and avg reward is 703.997346639572\n",
      "total reward after 25100 steps is 996.9620187200983 and avg reward is 691.0608531461793\n",
      "total reward after 25150 steps is 122.68260358067947 and avg reward is 678.2565300349568\n",
      "total reward after 25200 steps is 159.74245298884225 and avg reward is 672.6279841996819\n",
      "total reward after 25250 steps is 118.04834489203392 and avg reward is 660.5573292288371\n",
      "total reward after 25300 steps is 76.41618443319413 and avg reward is 648.4583576565396\n",
      "total reward after 25350 steps is 146.52845413331573 and avg reward is 630.9349862269179\n",
      "total reward after 25400 steps is 189.22131091128819 and avg reward is 626.3407771548227\n",
      "total reward after 25450 steps is 156.07821201529538 and avg reward is 606.3956770523964\n",
      "total reward after 25500 steps is 342.05153167433275 and avg reward is 603.8730569345327\n",
      "total reward after 25550 steps is 97.63514000679726 and avg reward is 593.7635817712118\n",
      "total reward after 25600 steps is 83.63471021977261 and avg reward is 570.8783557624602\n",
      "total reward after 25650 steps is 849.8753657260579 and avg reward is 568.2809421182357\n",
      "total reward after 25700 steps is 218.95377055813526 and avg reward is 555.349306023071\n",
      "total reward after 25750 steps is 95.01971162606284 and avg reward is 532.8211478991379\n",
      "total reward after 25800 steps is 949.1805398004699 and avg reward is 538.9167604289438\n",
      "total reward after 25850 steps is 4780.737386763977 and avg reward is 577.0121755541161\n",
      "total reward after 25900 steps is 242.53472056746165 and avg reward is 576.0614914957058\n",
      "total reward after 25950 steps is 190.3136804722609 and avg reward is 573.4457269217859\n",
      "total reward after 26000 steps is 426.9495368988661 and avg reward is 571.338380489241\n",
      "total reward after 26050 steps is 226.84045598877915 and avg reward is 561.2427790623074\n",
      "total reward after 26100 steps is 465.1243265264087 and avg reward is 554.8749502438127\n",
      "total reward after 26150 steps is 401.8818664423687 and avg reward is 539.5175088132004\n",
      "total reward after 26200 steps is 674.6287485510309 and avg reward is 540.7141377234209\n",
      "total reward after 26250 steps is 289.5262988083779 and avg reward is 541.1743576661968\n",
      "total reward after 26300 steps is 62.33163176396094 and avg reward is 517.3765068572933\n",
      "total reward after 26350 steps is 118.75228684178441 and avg reward is 498.4466548819359\n",
      "total reward after 26400 steps is 187.8371065864398 and avg reward is 497.12067385202937\n",
      "total reward after 26450 steps is 92.3785922881256 and avg reward is 492.8052716478927\n",
      "total reward after 26500 steps is 469.16478200921614 and avg reward is 484.5234198095269\n",
      "total reward after 26550 steps is 583.606612817839 and avg reward is 475.06959101789806\n",
      "total reward after 26600 steps is 70.12859117752346 and avg reward is 470.2218463294337\n",
      "total reward after 26650 steps is 1324.823619636306 and avg reward is 479.69610549189616\n",
      "total reward after 26700 steps is 183.34667600388065 and avg reward is 470.47708427932673\n",
      "total reward after 26750 steps is 373.0376131227387 and avg reward is 468.93436640207096\n",
      "total reward after 26800 steps is 102.84768945762735 and avg reward is 468.2114154746116\n",
      "total reward after 26850 steps is 3166.4957863067866 and avg reward is 497.6739157527624\n",
      "total reward after 26900 steps is 43.692059425441414 and avg reward is 496.28279544309476\n",
      "total reward after 26950 steps is 463.6282133670386 and avg reward is 487.80481044741174\n",
      "total reward after 27000 steps is 270.03814000160685 and avg reward is 473.6657289894321\n",
      "total reward after 27050 steps is 357.8059120718465 and avg reward is 471.53941371955517\n",
      "total reward after 27100 steps is 1123.856269299533 and avg reward is 480.5716484828661\n",
      "total reward after 27150 steps is 201.55722489689697 and avg reward is 459.2463842402351\n",
      "total reward after 27200 steps is 150.7779338838781 and avg reward is 460.08617987442005\n",
      "total reward after 27250 steps is 604.7952536083487 and avg reward is 465.6346403195601\n",
      "total reward after 27300 steps is 281.9783114579643 and avg reward is 462.25183154698976\n",
      "total reward after 27350 steps is 125.3961099719082 and avg reward is 460.050351414193\n",
      "total reward after 27400 steps is 67.1093197701706 and avg reward is 460.2175606654089\n",
      "total reward after 27450 steps is 154.44773591372928 and avg reward is 460.5858146331555\n",
      "total reward after 27500 steps is 924.069258362471 and avg reward is 469.21365039893004\n",
      "total reward after 27550 steps is 102.58108272783508 and avg reward is 467.7148204256381\n",
      "total reward after 27600 steps is 286.4066385113939 and avg reward is 467.54944869998604\n",
      "total reward after 27650 steps is 935.5045998287843 and avg reward is 476.4339000743127\n",
      "total reward after 27700 steps is 211.68778970032434 and avg reward is 477.41020531386937\n",
      "total reward after 27750 steps is 426.83754613469927 and avg reward is 477.4661652072921\n",
      "total reward after 27800 steps is 641.5449624609432 and avg reward is 483.3208262625901\n",
      "total reward after 27850 steps is 314.28719539280826 and avg reward is 484.20337133727946\n",
      "total reward after 27900 steps is 540.4491701984159 and avg reward is 486.26828540124194\n",
      "total reward after 27950 steps is 369.97820302971843 and avg reward is 484.5090283023065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward after 28000 steps is 1116.3981614835707 and avg reward is 492.6791362021729\n",
      "total reward after 28050 steps is 148.32799128330186 and avg reward is 492.3292376621425\n",
      "total reward after 28100 steps is 628.3601126052445 and avg reward is 495.69860657699877\n",
      "total reward after 28150 steps is 144.1622664684406 and avg reward is 496.39073837028985\n",
      "total reward after 28200 steps is 496.7734541882068 and avg reward is 498.48518836838673\n",
      "total reward after 28250 steps is 807.9552219256457 and avg reward is 502.3318838817934\n",
      "total reward after 28300 steps is 332.611923907606 and avg reward is 495.85305708277883\n",
      "total reward after 28350 steps is 814.3501279968007 and avg reward is 502.1743181359829\n",
      "total reward after 28400 steps is 473.1234838239684 and avg reward is 505.4328335069627\n",
      "total reward after 28450 steps is 779.1196480618778 and avg reward is 510.69398478820045\n",
      "total reward after 28500 steps is 478.2753822037463 and avg reward is 511.9067068316345\n",
      "total reward after 28550 steps is 489.64376263818565 and avg reward is 509.60841048981024\n",
      "total reward after 28600 steps is 304.8997594447618 and avg reward is 509.86227282007815\n",
      "total reward after 28650 steps is 448.56757116003376 and avg reward is 508.02740909281397\n",
      "total reward after 28700 steps is 347.35183164541206 and avg reward is 509.28248613165806\n",
      "total reward after 28750 steps is 380.93491530030815 and avg reward is 510.15698658488094\n",
      "total reward after 28800 steps is 445.4153369543311 and avg reward is 511.39624488743436\n",
      "total reward after 28850 steps is 986.6443822699152 and avg reward is 517.1304424559711\n",
      "total reward after 28900 steps is 173.18793347297816 and avg reward is 514.474285091774\n",
      "total reward after 28950 steps is 581.0885460915804 and avg reward is 502.01933637728575\n",
      "total reward after 29000 steps is 258.69775483340754 and avg reward is 501.4562909926465\n",
      "total reward after 29050 steps is 168.21180179378558 and avg reward is 497.07443029039524\n",
      "total reward after 29100 steps is 727.8512886522906 and avg reward is 491.9153528501397\n",
      "total reward after 29150 steps is 261.9206667914335 and avg reward is 491.8980254070995\n",
      "total reward after 29200 steps is 150.13711714157787 and avg reward is 491.8906724215685\n",
      "total reward after 29250 steps is 82.42272663958602 and avg reward is 487.28788393278626\n",
      "total reward after 29300 steps is 1541.8277072766607 and avg reward is 494.75697162860786\n",
      "total reward after 29350 steps is 602.431670380064 and avg reward is 493.0200722054383\n",
      "total reward after 29400 steps is 1039.186025400805 and avg reward is 494.0003163579955\n",
      "total reward after 29450 steps is 482.1761173384446 and avg reward is 493.13189008187044\n",
      "total reward after 29500 steps is 170.41212949420083 and avg reward is 490.1956029676084\n",
      "total reward after 29550 steps is 160.04180488000378 and avg reward is 489.9651209858302\n",
      "total reward after 29600 steps is 402.4357325389882 and avg reward is 492.16516085029434\n",
      "total reward after 29650 steps is 285.78364725073016 and avg reward is 494.179316619027\n",
      "total reward after 29700 steps is 96.06671632531655 and avg reward is 491.2789656906999\n",
      "total reward after 29750 steps is 149.1392797562446 and avg reward is 482.2542110045466\n",
      "total reward after 29800 steps is 767.27811804255 and avg reward is 487.51432030887713\n",
      "total reward after 29850 steps is 193.83672799641312 and avg reward is 472.729086673148\n",
      "total reward after 29900 steps is 83.81916938335533 and avg reward is 470.05487361214654\n",
      "total reward after 29950 steps is 355.71153848155495 and avg reward is 471.37969122041983\n",
      "total reward after 30000 steps is 143.69312742439567 and avg reward is 465.3283944002822\n",
      "total reward after 30050 steps is 158.536805429485 and avg reward is 462.92556776511105\n",
      "total reward after 30100 steps is 150.13541162284582 and avg reward is 454.4573016941385\n",
      "total reward after 30150 steps is 420.621240934112 and avg reward is 457.4366880676728\n",
      "total reward after 30200 steps is 360.7133712422809 and avg reward is 459.44639725020716\n",
      "total reward after 30250 steps is 252.2508661520621 and avg reward is 460.78842246280743\n",
      "total reward after 30300 steps is 79.67349035021957 and avg reward is 460.82099552197775\n",
      "total reward after 30350 steps is 68.98851141505855 and avg reward is 460.0455960947952\n",
      "total reward after 30400 steps is 349.6523038561984 and avg reward is 461.6499060242443\n",
      "total reward after 30450 steps is 515.9205169509927 and avg reward is 465.24832907360127\n",
      "total reward after 30500 steps is 2489.8582360914097 and avg reward is 486.7263961177721\n",
      "total reward after 30550 steps is 277.60948447855907 and avg reward is 488.5261395624897\n",
      "total reward after 30600 steps is 261.9912738614645 and avg reward is 490.3097051989066\n",
      "total reward after 30650 steps is 162.95097162695174 and avg reward is 483.44046125791544\n",
      "total reward after 30700 steps is 270.97631091877645 and avg reward is 483.960686661522\n",
      "total reward after 30750 steps is 746.6934021610385 and avg reward is 490.4774235668716\n",
      "total reward after 30800 steps is 494.60697954439814 and avg reward is 485.9316879643109\n",
      "total reward after 30850 steps is 167.20473951752166 and avg reward is 439.7963614918463\n",
      "total reward after 30900 steps is 210.65889132323503 and avg reward is 439.4776031994041\n",
      "total reward after 30950 steps is 135.7476171448007 and avg reward is 438.9319425661295\n",
      "total reward after 31000 steps is 107.91130564270452 and avg reward is 435.74156025356785\n",
      "total reward after 31050 steps is 85.56471719297645 and avg reward is 434.32880286560976\n",
      "total reward after 31100 steps is 1156.8504963921396 and avg reward is 441.24606456426704\n",
      "total reward after 31150 steps is 110.38066736538966 and avg reward is 438.3310525734973\n",
      "total reward after 31200 steps is 1008.6177767173631 and avg reward is 441.6709428551606\n",
      "total reward after 31250 steps is 89.02749144089886 and avg reward is 439.66595478148594\n",
      "total reward after 31300 steps is 807.1970108737859 and avg reward is 447.1146085725842\n",
      "total reward after 31350 steps is 2562.156878186978 and avg reward is 471.5486544860362\n",
      "total reward after 31400 steps is 465.7330502711166 and avg reward is 474.32761392288296\n",
      "total reward after 31450 steps is 396.40219891676526 and avg reward is 477.3678499891693\n",
      "total reward after 31500 steps is 75.80720573725294 and avg reward is 473.4342742264497\n",
      "total reward after 31550 steps is 106.97106557858513 and avg reward is 468.6679187540571\n",
      "total reward after 31600 steps is 161.92409122189906 and avg reward is 469.58587375450077\n",
      "total reward after 31650 steps is 109.86736217115228 and avg reward is 457.4363111798492\n",
      "total reward after 31700 steps is 206.9458593951975 and avg reward is 457.67230301376236\n",
      "total reward after 31750 steps is 156.05623200282233 and avg reward is 455.5024892025633\n",
      "total reward after 31800 steps is 720.3935916812164 and avg reward is 461.67794822479925\n",
      "total reward after 31850 steps is 302.9837766504549 and avg reward is 433.042828128236\n",
      "total reward after 31900 steps is 160.37685498079114 and avg reward is 434.20967608378953\n",
      "total reward after 31950 steps is 209.4162274464532 and avg reward is 431.6675562245836\n",
      "total reward after 32000 steps is 532.8679646315054 and avg reward is 434.2958544708826\n",
      "total reward after 32050 steps is 98.60890024434914 and avg reward is 431.7038843526076\n",
      "total reward after 32100 steps is 237.80750614446583 and avg reward is 422.84339672105693\n",
      "total reward after 32150 steps is 145.93039075268462 and avg reward is 422.2871283796147\n",
      "total reward after 32200 steps is 121.80915260581591 and avg reward is 421.99744056683414\n",
      "total reward after 32250 steps is 203.21861685287791 and avg reward is 417.98167419927944\n",
      "total reward after 32300 steps is 395.90142864023846 and avg reward is 419.12090537110214\n",
      "total reward after 32350 steps is 151.9166322156604 and avg reward is 419.3861105935396\n",
      "total reward after 32400 steps is 96.37924514552975 and avg reward is 419.6788098472933\n",
      "total reward after 32450 steps is 104.17102701579908 and avg reward is 419.176042758314\n",
      "total reward after 32500 steps is 213.75835389114965 and avg reward is 412.0729337136008\n",
      "total reward after 32550 steps is 109.11421388436301 and avg reward is 412.13826502516605\n",
      "total reward after 32600 steps is 213.12657557392157 and avg reward is 411.40546439579134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward after 32650 steps is 704.4635218069856 and avg reward is 409.09505361557336\n",
      "total reward after 32700 steps is 663.768108296684 and avg reward is 413.61585680153695\n",
      "total reward after 32750 steps is 158.07840945874995 and avg reward is 410.9282654347775\n",
      "total reward after 32800 steps is 1016.2753871379728 and avg reward is 414.6755696815478\n",
      "total reward after 32850 steps is 169.44662990671583 and avg reward is 413.2271640266868\n",
      "total reward after 32900 steps is 490.0625604441802 and avg reward is 412.72329792914445\n",
      "total reward after 32950 steps is 210.72244677196767 and avg reward is 411.1307403665669\n",
      "total reward after 33000 steps is 210.80049290874604 and avg reward is 402.07476368081865\n",
      "total reward after 33050 steps is 142.6478173521697 and avg reward is 402.0179619415074\n",
      "total reward after 33100 steps is 970.4740473961638 and avg reward is 405.43910128941656\n",
      "total reward after 33150 steps is 1071.9608000785042 and avg reward is 414.7170866255172\n",
      "total reward after 33200 steps is 515.9485654080672 and avg reward is 414.9088377377158\n",
      "total reward after 33250 steps is 192.41867851551825 and avg reward is 408.75347230361456\n",
      "total reward after 33300 steps is 158.18326361884067 and avg reward is 407.0091857007269\n",
      "total reward after 33350 steps is 1807.5115520164081 and avg reward is 416.94079994092294\n",
      "total reward after 33400 steps is 242.10053030876827 and avg reward is 414.6305704057709\n",
      "total reward after 33450 steps is 349.33651671628047 and avg reward is 410.33273909231497\n",
      "total reward after 33500 steps is 429.50620355209634 and avg reward is 409.84504730579846\n",
      "total reward after 33550 steps is 1014.2533689526717 and avg reward is 415.0911433689433\n",
      "total reward after 33600 steps is 238.59372982768627 and avg reward is 414.42808307277255\n",
      "total reward after 33650 steps is 687.5087252967954 and avg reward is 416.8174946141402\n",
      "total reward after 33700 steps is 774.8958955609653 and avg reward is 421.09293525329565\n",
      "total reward after 33750 steps is 647.7986123913304 and avg reward is 423.7615722242059\n",
      "total reward after 33800 steps is 148.18055286554264 and avg reward is 420.78922438331807\n",
      "total reward after 33850 steps is 268.3106450831228 and avg reward is 413.6058870114502\n",
      "total reward after 33900 steps is 153.18200518129225 and avg reward is 413.4058277285333\n",
      "total reward after 33950 steps is 366.56059969642706 and avg reward is 411.26054826458187\n",
      "total reward after 34000 steps is 264.97378601656453 and avg reward is 411.32330857641335\n",
      "total reward after 34050 steps is 185.61783351879689 and avg reward is 411.49736889366335\n",
      "total reward after 34100 steps is 216.44255738508656 and avg reward is 406.38328158099137\n",
      "total reward after 34150 steps is 305.4157879980887 and avg reward is 406.818232793058\n",
      "total reward after 34200 steps is 557.8683651183433 and avg reward is 410.8955452728257\n",
      "total reward after 34250 steps is 1528.2148764582948 and avg reward is 425.35346677101285\n",
      "total reward after 34300 steps is 279.2109736179898 and avg reward is 412.7272994344261\n",
      "total reward after 34350 steps is 653.2666010498625 and avg reward is 413.235648741124\n",
      "total reward after 34400 steps is 143.91009632612167 and avg reward is 404.28288945037724\n",
      "total reward after 34450 steps is 216.13299850386045 and avg reward is 401.6224582620313\n",
      "total reward after 34500 steps is 165.5436820182699 and avg reward is 401.5737737872721\n",
      "total reward after 34550 steps is 361.7477787284459 and avg reward is 403.59083352575647\n",
      "total reward after 34600 steps is 686.8916587994402 and avg reward is 406.4353927883609\n",
      "total reward after 34650 steps is 346.40644053031593 and avg reward is 407.04162072115673\n",
      "total reward after 34700 steps is 1171.9339292863979 and avg reward is 417.8002928507675\n",
      "total reward after 34750 steps is 178.27434188081787 and avg reward is 418.09164347201323\n",
      "total reward after 34800 steps is 148.2557057733452 and avg reward is 411.9014193493212\n",
      "total reward after 34850 steps is 533.7224959834859 and avg reward is 415.30027702919193\n",
      "total reward after 34900 steps is 471.5931283265398 and avg reward is 419.1780166186238\n",
      "total reward after 34950 steps is 532.1994470186835 and avg reward is 420.942895703995\n",
      "total reward after 35000 steps is 1385.8381330454986 and avg reward is 433.3643457602061\n",
      "total reward after 35050 steps is 748.7575013513676 and avg reward is 439.266552719425\n",
      "total reward after 35100 steps is 2387.330364359105 and avg reward is 461.6385022467876\n",
      "total reward after 35150 steps is 2327.7817233364003 and avg reward is 480.71010707081064\n",
      "total reward after 35200 steps is 1458.3856022569926 and avg reward is 491.68682938095765\n",
      "total reward after 35250 steps is 1430.0030996599496 and avg reward is 503.46435171603645\n",
      "total reward after 35300 steps is 1065.8288777777627 and avg reward is 513.3259055903119\n",
      "total reward after 35350 steps is 3869.473135687127 and avg reward is 551.3307518330327\n",
      "total reward after 35400 steps is 1327.5926339040652 and avg reward is 561.1101551335113\n",
      "total reward after 35450 steps is 1864.3526616989377 and avg reward is 574.5944765809908\n",
      "total reward after 35500 steps is 1162.2617855247368 and avg reward is 561.318512075324\n",
      "total reward after 35550 steps is 753.0676129958262 and avg reward is 566.0730933604966\n",
      "total reward after 35600 steps is 1147.2986394657319 and avg reward is 574.9261670165394\n",
      "total reward after 35650 steps is 1150.8077595861857 and avg reward is 584.8047348961317\n",
      "total reward after 35700 steps is 541.3122040003504 and avg reward is 587.5080938269474\n",
      "total reward after 35750 steps is 587.0031750993849 and avg reward is 585.911191556331\n",
      "total reward after 35800 steps is 834.524682248245 and avg reward is 589.3103685833694\n",
      "total reward after 35850 steps is 612.1201013089503 and avg reward is 593.7595222012837\n",
      "total reward after 35900 steps is 749.2466900865265 and avg reward is 599.1454001889167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/pgi/anaconda3/envs/map556/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-ca5c109f76fa>\", line 27, in <module>\n",
      "    next_state, reward, done, _ = env.step(action)\n",
      "  File \"/home/pgi/map556/challenge2/peng-wei/Angrybird.py\", line 65, in step\n",
      "    self.X[1:] = self.dynamique_pos(action)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pgi/anaconda3/envs/map556/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pgi/anaconda3/envs/map556/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/pgi/anaconda3/envs/map556/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/pgi/anaconda3/envs/map556/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/pgi/anaconda3/envs/map556/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/pgi/anaconda3/envs/map556/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/pgi/anaconda3/envs/map556/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/pgi/anaconda3/envs/map556/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/pgi/anaconda3/envs/map556/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/pgi/anaconda3/envs/map556/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/pgi/anaconda3/envs/map556/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ca5c109f76fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhand_made_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mhand_made_next_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/map556/challenge2/peng-wei/Angrybird.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamique_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectoire\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/map556/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/map556/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2048\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/map556/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1437\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/map556/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/map556/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/map556/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/map556/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from Angrybird import AngryBird\n",
    "scale = np.array([10., 100., 50.])\n",
    "with tf.device('GPU:0'):\n",
    "    tf.random.set_seed(336699)\n",
    "    agent = Agent(2)\n",
    "    env = AngryBird()\n",
    "    episods = 100000\n",
    "    ep_reward = []\n",
    "    total_avgr = []\n",
    "    target = False\n",
    "\n",
    "    for s in range(episods):\n",
    "        if target == True:\n",
    "            break\n",
    "        total_reward = 0\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        ## model of wing\n",
    "        cost = 0\n",
    "\n",
    "        while not done:\n",
    "            hand_made_state = state / scale\n",
    "            if state[0] == 11.:\n",
    "                action = np.zeros(2)\n",
    "            else:\n",
    "                action = agent.act(hand_made_state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            hand_made_next_state = next_state / scale\n",
    "            agent.savexp(hand_made_state, hand_made_next_state, action, done, reward)\n",
    "            agent.train()\n",
    "            #print(state, reward, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "        if done and s % 50 == 0:\n",
    "            ep_reward.append(total_reward)\n",
    "            avg_reward = np.mean(ep_reward[-100:])\n",
    "            total_avgr.append(avg_reward)\n",
    "            print(\"total reward after {} steps is {} and avg reward is {}\".format(s, total_reward, avg_reward))\n",
    "            if int(avg_reward) < 50:\n",
    "                target = True\n",
    "        if (s + 1) % 1000 == 0:\n",
    "            agent.actor_main.save_weights(\"td3_actor_{}\".format(s+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weight in agent.actor_main.weights:\n",
    "    pass\n",
    "    #print(tf.Variable(weight.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFoOf-MYf-Ep"
   },
   "outputs": [],
   "source": [
    "ep = [i  for i in range(len(total_avgr))]\n",
    "plt.plot( range(len(total_avgr)),total_avgr,'b')\n",
    "plt.title(\"Avg Test Aeward Vs Test Episods\")\n",
    "plt.xlabel(\"Test Episods\")\n",
    "\n",
    "plt.ylabel(\"Average Test Reward\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iffzAWwBELNL",
    "outputId": "07816cb3-31f4-4ed0-8817-09e8c7b8bd5e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for i in range(10):\n",
    "    hand_made_state = state / scale \n",
    "    action = agent.act(hand_made_state)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    print(action, reward)\n",
    "    state = next_state\n",
    "traj = np.array(env.trajectoire)\n",
    "plt.plot(traj[:, 1], traj[:, 2])#, label=\"{}\".format())\n",
    "plt.scatter(traj[-1][1], traj[-1][2])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPy/vODWhRXFnIkwHUNOvhl",
   "include_colab_link": true,
   "name": "td3withtau.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
