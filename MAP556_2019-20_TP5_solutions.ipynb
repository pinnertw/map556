{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP556, Ecole Polytechnique, 2020-21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 5 - Régression pour l'approximation d'espérance conditionnelle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1.  Un exemple de programmation dynamique pour l'arrêt optimal - l'option \"Put Bermuda\".\n",
    "\n",
    "On considère le processus stochastique à deux pas \n",
    "$$X_i = x_0 \\ e^{-\\frac12 \\sigma^2 T_i + \\sigma W_{i}}, \\quad\n",
    "\\qquad i=0,1,2,\n",
    "$$\n",
    "où $x_0$ et $\\sigma$ sont deux paramètres positifs, $T_i=i$, et $(W_i)_{0\\le i \\le 2}$ est un processus à temps discret définit comme suit: $W_0 = 0$, et \n",
    "\n",
    "- la v.a.  $W_{1}$ suit une loi Gaussienne $\\mathcal{N}(0,T_1)$,\n",
    "\n",
    "\n",
    "- $W_{2} = W_{1} + \\Delta W$, où $\\Delta W$ est une v.a. de loi $\\mathcal{N}(0,T_2 - T_1)$ indépendante de $W_{1}$.\n",
    "\n",
    "On remarquera que $(W_i)_{0\\le i \\le 2}$ est un mouvement Brownien pris aux instants $T_i$.\n",
    "En particulier, c'est une chaîne de Markov par rapport à sa filtration $(\\mathcal{F}_0, \\mathcal{F}_1, \\mathcal{F}_2)$, où $\\mathcal{F}_i = \\sigma(W_0, \\dots, W_i)$.\n",
    "\n",
    "Le processus $(X_i)_{0\\le i \\le 2}$ est appelé mouvement Brownien géometrique.\n",
    "\n",
    "\n",
    "Dans la suite, le processus $X$ représente la valeur d'un actif sur un marché (par exemple, une action).\n",
    "Le contrat financier _option Put Bermuda_ est un exemple de jeu à arrêt optimal: l'acheteur du contrar paye au vendeur un prix $u_0$ à l'instant $T_0$, et gagne en échange le droit de recevoir le montant $(K-X_t)^+$ à une date $t\\in\\{0,1,2 \\}$ de son choix. \n",
    "La constante $K > 0$ est fixée dès le départ.\n",
    "\n",
    "On peut justifier que le prix à attribuer à cette option à la date $T_0$ est donné par\n",
    "\n",
    "$$u_0 = \\sup_{\\tau \\in \\mathcal{T}_2 } {\\mathbb E}[ (K - X_\\tau)^+ ] ,$$\n",
    "\n",
    "où $\\mathcal{T}_2$ est l'ensemble de temps d'arrêt à valeurs dans $\\{0,T_1,T_2\\}$ par rapport à la filtration $(\\mathcal{F}_i)_{0\\le i \\le 2}$. \n",
    "\n",
    "\n",
    "On souhaite évaluer $u_0$ par Monte-Carlo. \n",
    "On rappelle l'équation de programmation dynamique pour l'arrêt optimal: en posant $Y_i = \\mbox{ess}\\sup_{\\tau \\in \\mathcal{T}_2: \\tau \\ge i} {\\mathbb E}[ (K - X_\\tau)^+|\\mathcal F_{i}]$, on a\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&Y_2 = (K-X_2)^+\n",
    "\\\\\n",
    "&Y_i = \\max \\left( (K-X_i)^+, {\\mathbb E}[Y_{i+1}|\\mathcal{F}_i] \\right)\n",
    "\\qquad i = 0, 1.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Question préliminaire: \n",
    "Montrer que $Y_i$ est de la forme $Y_i= u_i (W_i)$ pour une fonction mesurable $u_i: \\mathbb{R} \\to \\mathbb{R}$, et écrire l'équation recursive satisfaite par les fonctions $u_i$.\n",
    "En déduire que le prix de l'option Bermuda s'écrit\n",
    "\n",
    "$$\n",
    "u_0 = Y_0\n",
    "= \\max \\left\\{ (K-x_0)^+, {\\mathbb E} \\left[ \\max\\left( (K - X_1)^+, v_1(W_1) \\right) \\right] \\right\\},\n",
    "$$\n",
    "\n",
    "où $v_1(W_1) = {\\mathbb E}[(K-X_2)^+|W_1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ On note $(W_1^m,W_2^m)_{1 \\le m \\le M}$ un échantillon de tirages i.i.d. du couple $(W_1,W_2)$, et on pose $X_i^m = x_0 \\, e^{-\\frac12 \\sigma^2 T_i \\, + \\, \\sigma \\, W_i^m}$ pour tout $m$.\n",
    "\n",
    "\n",
    "1. __Prix _benchmark___: \tdans cette question, on utilisera la formule explicite\n",
    "\t\n",
    "    $$\n",
    "  v_1(W_1) = {\\mathbb E}[(K-X_2)^+|W_1] = \\mathrm{P}(W_{1}),\n",
    "\t$$\n",
    "    \n",
    "\toù, pour tout $w \\in \\mathbb{R}$,\n",
    "\t$$\n",
    "\t\\mathrm{P}(w) = K \\, N(-d_2) - x \\, N(-d_1)\n",
    "\t$$\n",
    "    \n",
    "\tavec\n",
    "\t$$\n",
    "\tx = x_0  \\, e^{-\\frac12 \\sigma^2 T_1 + \\sigma \\, w},\n",
    "\t\\qquad d_2 = \\frac{\\log(x/K)}{\\sigma \\sqrt{T_2-T_1}} - \\frac12 \\sigma \\sqrt{T_2-T_1},\n",
    "\t\\qquad d_1 = d_2 + \\sigma \\sqrt{T_2-T_1},\n",
    "\t$$\n",
    "    \n",
    "\toù $N(z) = \\int_{-\\infty}^z e^{-y^2/2} \\frac{dy}{\\sqrt{2 \\pi}}$ est la fonction de répartition gaussienne. accessible via la fonction `scipy.stats.norm.cdf`.\n",
    "    \n",
    "    (Remarque: Dans la terminologie financière, la fonction $\\mathrm{P}$ est le prix d'une option Put (non Bermuda, mais *Européen*) dans le modèle de Black-Scholes.)\n",
    "    \n",
    "    __1 (a)__. Coder cette formule dans la fonction putBlackScholes. Vérifier que pour les paramètres $x_0=1$, $T_1=1$, $T_2=2 $, $K=1.2$, $\\sigma=0.2$, on obtient bien $\\mathrm{P}( 0) \\approx 0.2374$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from time import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parametres\n",
    "K = 1.2\n",
    "x0 = 1.\n",
    "sigma = 0.2\n",
    " \n",
    "T2 = 2.\n",
    "T1 = T2 / 2.\n",
    " \n",
    "M = int(5e3)\n",
    "\n",
    "def pos_part(x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "## Q1 (a): formule explicite\n",
    "##         pour l'esperance conditionnelle \n",
    "###################################################\n",
    " \n",
    "def putBlackScholes(x0, T1, T2, K, W1, sigma):\n",
    "    \"\"\"\n",
    "    La fonction v_1(W1) de la question 1.(a)\n",
    "    \n",
    "    Autrement dit: le prix en T1 du Put Black-Scholes de maturite T2\n",
    "    en fonction de la valeur courante du mouv Brownien en T1.\n",
    "     \n",
    "    W1: un array numpy, contenant les valeurs courantes\n",
    "    du mouv Brownien en T1\n",
    "    \"\"\"\n",
    "    sigmaSqrtDeltaT = sigma * np.sqrt(T2 - T1)\n",
    "\n",
    "    ## Output: un array de la meme taille que W    \n",
    "    ln_x = np.log(x0) + sigma*W1 - 0.5*sigma*sigma*T1\n",
    "    \n",
    "    d2 = (ln_x - np.log(K)) / sigmaSqrtDeltaT - 0.5*sigmaSqrtDeltaT\n",
    "    d1 = d2 + sigmaSqrtDeltaT\n",
    "    \n",
    "    return  K*norm.cdf(-d2) - np.exp(ln_x)*norm.cdf(-d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1 (b)__ S'il reste du temps après avoir abordé les questions 2-3-4 ci-dessous, démontrer la formule donnée pour la fonction $v_1$.\n",
    "\n",
    "La connaissance explicite de la fonction $v_1$ permet d'écrire l'estimateur\n",
    "$$\n",
    "u_0^{M} = \\max \\Bigl\\{\n",
    "(K-x_0)^+, \\frac 1M \\sum_{m = 1}^M \\max\\left( (K - X_{1}^m)^+, \\mathrm{P}(W_{1}^m) \\right) \\Bigr\\}.\n",
    "$$\n",
    "\n",
    "__1 (c)__ Simuler cet estimateur dans le code suivant. Pour calculer le maximum $\\max(a,b)$ entre deux nombres, on pourra utiliser la fonction `numpy.maximum(a,b)`.\n",
    "\n",
    "Pour les valeurs considérées des paramètres, on peut montrer que l'on a\n",
    "\n",
    "$$\n",
    "{\\mathbb E} \\left[ \\max\\left( (K - X_1)^+, v_1(W_1) \\right) \\right] > (K-x_0)^+.\n",
    "$$\n",
    "\n",
    "L'estimateur $u_0^{M}$ satisfait-il un TCL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "## On genere les tirages gaussiens et on construit\n",
    "## le mouv Brownien W et le mouv Brownien géometrique\n",
    "## aux instants T1 et T2\n",
    "###################################################\n",
    "def MBG(x0, T, sigma, W):\n",
    "    \"\"\"\n",
    "    Processus X: mouvement Brownien géometrique à\n",
    "    l'instant T, de parametre de volatilite sigma,\n",
    "    a partir de la valeur du mouvement Brownien W\n",
    "    \"\"\"\n",
    "    return x0 * np.exp(-0.5*sigma*sigma*T + sigma * W)\n",
    " \n",
    "time0 = time()\n",
    " \n",
    "#################################################\n",
    "## TO DO: Remplacer W1, W2 avec un echantillon de\n",
    "## tirages du mouvement Brownien aux dates T1 et T2\n",
    "## et X1, X2 avec le MBG correspondant\n",
    "W1 = np.sqrt(T1) * np.random.randn(M) # gaussiennes N(0,T_1)\n",
    "W2 = W1 + np.sqrt(T2-T1) * np.random.randn(M) # W1 + gaussiennes N(0,T_2-T_1) independantes\n",
    "\n",
    "X1 = MBG(x0, T1, sigma, W1)\n",
    "X2 = MBG(x0, T2, sigma, W2)\n",
    "################################################\n",
    " \n",
    "time0_1 = time()\n",
    " \n",
    "timeSimulations = time0_1 - time0\n",
    " \n",
    "###################################################\n",
    "### 1. Prix Benchmark\n",
    "###################################################\n",
    " \n",
    "time1 = time()\n",
    " \n",
    "v_1 = putBlackScholes(x0, T1, T2, K, W1, sigma)\n",
    " \n",
    "################################################\n",
    "## TO DO: completer avec le calcul du prix\n",
    "## benchmark u_0^M et l'estimation de la variance\n",
    "## asymptotique de l'estimateur\n",
    "echantillon = np.maximum(pos_part(K - X1), v_1) ## echantillon de taille M\n",
    "\n",
    "prix_benchmark = np.maximum( pos_part(K - x0), np.mean(echantillon) )\n",
    "\n",
    "## TCL par méthode delta\n",
    "var_TCL = np.var(echantillon)\n",
    "\n",
    "################################################ \n",
    "rayonIC = 1.96 * np.sqrt(var_TCL/M)\n",
    " \n",
    "time2 = time()\n",
    " \n",
    "print(\"Prix benchmark = %1.4f +/- %1.4f \\n\" %(prix_benchmark, rayonIC) )\n",
    "print(\"Erreur relative (TCL) = %1.3f \\n\" %(rayonIC / prix_benchmark) )\n",
    "print(\"Time: %1.4f \\n\" %(time2 - time1 + timeSimulations) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Prix par régression empirique:__ \n",
    "\n",
    "    - On choisit comme espace d'approximation l'espace $\\Phi$ engendré par les fonctions indicatrices de $n$ intervalles disjoints:\n",
    "$$\n",
    "\\phi_k = 1_{I_k},\n",
    "\\quad\n",
    "\\mbox{où }\n",
    "I_k = \\left[-a + (k-1) \\delta, -a + k \\delta \\right[;\n",
    "\\quad \\delta = \\frac{2a}n;\n",
    "\\quad k = 1, \\dots, n\n",
    "$$\n",
    "$$\n",
    "\\Phi = \\text{Vect}(\\phi_1,\\dots, \\phi_n)\n",
    "= \\left\\{\\sum_{k=1}^n \\alpha_k \\phi_k(\\cdot): \\alpha_1, \\dots, \\alpha_n \\in \\mathbb{R} \\right\\}.\n",
    "$$\n",
    "On notera $\\alpha \\cdot \\phi(\\cdot) = \\sum_{k=1}^n \\alpha_k \\phi_k(\\cdot)$.\n",
    "\n",
    "    - L'approximation empirique de la fonction $v_1(\\cdot)$ est donnée par\n",
    "$$\n",
    "\\tilde v_1(\\cdot) = \\sum_{k=1}^{n} \\alpha_k^* \\ 1_{I_k}(\\cdot)\n",
    "$$\n",
    "où\n",
    "$$ \\label{e:regrEmp}\n",
    "\\begin{aligned}\n",
    "\\alpha^* \\in \\underset{\\alpha\\in \\mathbb{R}^n}{\\rm arg\\min}\n",
    "\\ \\sum_{m = 1}^M\n",
    "\\left((K-X_2^m)^+ - \\alpha \\cdot \\phi(W_1^m)\\right)^2.\n",
    "\\end{aligned}\n",
    "$$\n",
    "Si l'argmin n'est pas unique, on choisira le $\\alpha^*$ de norme minimale dans $\\mathbb{R}^n$.\n",
    "\n",
    "L'estimateur par régression empirique du prix du Put Bermuda est maintenant\n",
    "$$\n",
    "\\tilde{u}_0^{M} = \n",
    "\\max \\Bigl\\{\n",
    "(K - x_0)^+, \\frac 1M \\sum_{m=1}^M \\tilde u_1(W_1^m)\n",
    "\\Bigr\\}\n",
    "$$\n",
    "où $\\tilde u_1(W_1^m) =  \\max \\left( (K - X_{1}^m)^+, \\tilde{v}_1(W_1^m) \\right)$.\n",
    "\n",
    "__ 2 (a)__  Rappeler l'expression des coefficients $\\alpha^*_k$, et l'utiliser pour compléter la fonction\n",
    "coeffsRegressionEmpirique. Compléter le calcul de l'estimateur $\\tilde{u}_0^{M}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "### 2. Prix par regression empirique\n",
    "###################################################\n",
    " \n",
    "##################################\n",
    "### On genere les cellules I_k\n",
    "##################################\n",
    "\n",
    "# Troncature du domaine pour N(0, T1)\n",
    "a = 3.*np.sqrt(T1) \n",
    " \n",
    "## Dimension espace d'approximation \n",
    "\n",
    "# A partir d'estimation d'erreur sur la regression\n",
    "# un bon choix de n (nombre de regresseurs) est\n",
    "# n de l'ordre de M^{ d / (d+2) } où d est la dim de l'espace\n",
    "# --> vérifier avec cours 6\n",
    "n = int(M**(1./3))\n",
    " \n",
    "intervals = np.linspace(-a, a, n+1)\n",
    "\n",
    "####################################################\n",
    "## TO DO: calculer\n",
    "## - Les coefficients de regression empirique alpha\n",
    "## - Le vecteur v_1_tilde(W1) de taille M\n",
    "##   dans l'array approx_empirique_T1\n",
    "####################################################\n",
    "def regressionEmpirique(W1, W2, intervals, T2, K, x0, sigma):\n",
    "    step = intervals[1] - intervals[0]\n",
    "    alpha = np.zeros(intervals.size - 1)\n",
    "    \n",
    "    approx_empirique_T1 = np.zeros(M)\n",
    "     \n",
    "    for k in range(intervals.size - 1):\n",
    "        leftPoint = intervals[k]\n",
    "        \n",
    "        insideCell = np.logical_and( leftPoint <= W1, W1 < leftPoint+step )         \n",
    "        \n",
    "        MBG_T2 = MBG(x0, T2, sigma, W2[insideCell])\n",
    "        \n",
    "        #############################################\n",
    "        ## TO DO: Completer avec le calcul des\n",
    "        ## coefficients alpha[k]\n",
    "        number_inside_cell = np.sum(insideCell)\n",
    "        \n",
    "        if number_inside_cell != 0:\n",
    "            alpha[k] = np.sum( pos_part(K - MBG_T2) ) / number_inside_cell\n",
    "        #############################################\n",
    "        \n",
    "        #############################################\n",
    "        ## TO DO: Completer avec le calcul de l'approximation\n",
    "        ## empirique v_1_tilde(W1) \n",
    "        approx_empirique_T1[insideCell] = alpha[k]\n",
    "        #############################################\n",
    "     \n",
    "    return alpha, approx_empirique_T1\n",
    " \n",
    "time3 = time()\n",
    " \n",
    "alpha, approx_empirique_T1 = regressionEmpirique(W1, W2, intervals, T2, K, x0, sigma) \n",
    "\n",
    "################################################\n",
    "## TO DO: Completer avec le calcul du prix\n",
    "## par regression empirique u_tilde_0^M \n",
    "\n",
    "echantillon = np.maximum(pos_part(K - X1), approx_empirique_T1) ## echantillon de taille M\n",
    "\n",
    "prix_RegrEmp = np.maximum( pos_part(K - x0), np.mean(echantillon) )\n",
    "################################################\n",
    " \n",
    "time4 = time()\n",
    " \n",
    "print(\"Prix par regression empirique = %1.4f\" %prix_RegrEmp)\n",
    "print(\"Time: %1.4f \\n\" %(time4 - time3 + timeSimulations))\n",
    " \n",
    "######################################\n",
    "## On peut afficher la vraie fonction\n",
    "## v_1 et son approximation empirique\n",
    "## pour comparaison\n",
    "#####################################\n",
    "x = np.linspace(-a, a, 100)\n",
    " \n",
    "v_1_exact = putBlackScholes(x0, T1, T2, K, x, sigma)\n",
    " \n",
    "plt.plot(x, v_1_exact, color=\"b\", label=\"$v_1$\")\n",
    " \n",
    "plt.step(intervals, np.append(alpha, alpha[-1]), where=\"post\", color=\"r\", label=r\"$\\tilde{v}_1$\")\n",
    " \n",
    "plt.xlabel(\"valeurs de $W_1$\", fontsize=17)\n",
    "plt.legend(loc=\"best\", fontsize=20)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __Prix _Simulations dans les simulations:___ L'estimateur est\n",
    "$$\n",
    "\\hat{u}_0^{M} = \\max \\Bigl\\{ (K-x_0)^+,\n",
    "\\frac 1M \\sum_{m = 1}^M \\max\\left( (K - X_{1}^m)^+, \\hat{v}_{1}^m \\right)\n",
    "\\Bigr\\}\n",
    "$$\n",
    "où pour tout $m$, $\\hat{v}_{1}^m$ est obtenue à partir d'un échantillon de $M$ simulations i.i.d.\n",
    "de la loi de $W_2$ conditionellement à $W_1$, notées \n",
    "$(W_2^{m,m'})_{1 \\le m' \\le M}$:\n",
    "$$\n",
    "\\hat{v}_{1}^m = \\frac1{M} \\sum_{m' = 1}^M \\bigl(K - x_0 \\, e^{-\\frac12 \\sigma^2 T_2 + \\sigma \\, W_2^{m,m'}} \\bigr)^+.\n",
    "$$\n",
    "    (a) Quelle est la loi de $W_2$ conditionelle à $W_1 = x$? Pour chaque $m$, simuler les $M$ tirages $W_2^{m, m'}$ suivant cette loi conditionnelle en $x =W_1^m$.\n",
    "    \n",
    "    (b) Compléter le calcul de cet estimateur dans le code ci-dessous, et comparer avec les méthodes précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "#### 3. Prix \"simulations dans les simulations\"\n",
    "###################################################\n",
    " \n",
    "###################################################\n",
    "## On genere M tirages de X2 pour chaque valeur\n",
    "## dans l'echantillon X1.\n",
    "## Il faudra donc repeter les tirages de M gaussiennes iid \n",
    "## POUR CHAQUE valeur de X1.\n",
    "###################################################\n",
    "sum_u_1 = 0.\n",
    " \n",
    "time7 = time()\n",
    " \n",
    "for m, w1 in enumerate(W1):\n",
    "    G = np.random.randn(M)\n",
    "     \n",
    "    ###################################################\n",
    "    ## To Do: completer avec\n",
    "    ## - les tirages de W_2 conditionnellement a W1=w1\n",
    "    ## - la mise a jour de la somme des contributions à \n",
    "    ##   la variable u_1\n",
    "    W2 = w1 + np.sqrt(T2 - T1) * G\n",
    "    \n",
    "    ## On implemente v_1_hat\n",
    "    v_1_hat = np.mean( pos_part(K - MBG(x0, T2, sigma, W2)) )\n",
    "    \n",
    "    max_courant = np.maximum( pos_part(K - MBG(x0, T1, sigma, w1)), v_1_hat)\n",
    "    \n",
    "    sum_u_1 += max_courant\n",
    "    ###################################################\n",
    "\n",
    "u_0 = np.maximum( np.maximum(K-x0,0.), sum_u_1/M )\n",
    " \n",
    "time8 = time()\n",
    " \n",
    "print(\"Prix Sim dans sim = %1.4f\" %u_0)\n",
    "print(\"Time: %1.4f\" %(time8 - time7), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. __Prix Longstaff-Schwartz:__\n",
    "on construit un temps d'arrêt optimal $\\tau^*$, que l'on simule ensuite à partir des tirages $(W_1^m, W_2^m)$.\n",
    "Rappelons les propriétés suivantes pour le temps d'arrêt optimal:\n",
    "\n",
    "    (a) On pose $\\tau^\\star = \\min\\{i\\ge 0 : Y_i = (K - X_i)^+ \\}$ et on note $(Y^\\star_i)_{0\\le i \\le 2}$ le processus arrêté $Y^\\star_i = Y_{i \\wedge \\tau^\\star}$. Montrer que $\\tau^\\star \\in \\mathcal{T}_2$ et que\n",
    "\n",
    "    $$\n",
    "    Y^\\star_i = \\mathbb{E}[Y^\\star_{i+1}|\\mathcal{F}_i].\n",
    "    $$\n",
    "    (Indication: écrire $Y_{i \\wedge \\tau^\\star} = 1_{i < \\tau^\\star} Y_i \\, + \\, 1_{i \\ge \\tau^\\star} Y_{\\tau^\\star}$ et observer que sur l'événement $\\{i < \\tau^\\star\\}$, on a $Y_i = \\mathbb{E}[Y_{i+1}|\\mathcal{F}_i]$.)\n",
    "\n",
    "    (b) Utiliser $(Y^\\star_i)_{0\\le i \\le 2}$ pour montrer que $\\tau^\\star$ est un temps d'arrêt optimal.\n",
    "\n",
    "On obtient l'estimateur\n",
    "$$\n",
    "\\check{u}_0^M = \\frac1{M} \\sum_{m = 1}^M (K - X^{m}_{\\tau_m})^+,\n",
    "\\qquad\n",
    "\\mbox{où }\n",
    "\\tau_m = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "0 & \\mbox{si } (K-x_0)^+ \\ge \\tilde u_0^M\n",
    "\\\\\n",
    "1 & \\mbox{si } (K-x_0)^+ < \\tilde u_0^M \\mbox{ et } (K-X_1^m)^+ \\ge \\tilde{u}_1(W_1^m)\n",
    "\\\\\n",
    "2 & \\mbox{sinon}.\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Compléter le calcul de cet estimateur dans le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "### 4. Prix Longstaff-Schwartz\n",
    "###################################################\n",
    "time5 = time()\n",
    " \n",
    "def tempsArretOptimal(X1, approx_empirique_T1, K, x0, M):\n",
    "    ## On réutilise l'approximation empirique definie\n",
    "    ## plus haut, correspondant a v_1_tilde\n",
    "    gain_T1 = np.maximum(K - X1, 0.)\n",
    "    \n",
    "    u_1_tilde = np.maximum(gain_T1, approx_empirique_T1)\n",
    "     \n",
    "    mean_0 = np.mean(u_1_tilde)\n",
    "     \n",
    "    if np.maximum((K-x0), 0.) >= mean_0:\n",
    "        return np.zeros(M)\n",
    "    else:\n",
    "        tau = 1 * (u_1_tilde <= gain_T1) \\\n",
    "              + 2 * (u_1_tilde > gain_T1)\n",
    "     \n",
    "    return tau\n",
    " \n",
    "###################################################\n",
    "## To Do: completer avec le calcul\n",
    "## - du temps d'arret optimal tau (echantillon tau_m)\n",
    "## - de l'estimateur Longstaff-Schwartz du prix\n",
    "##\n",
    "tau = tempsArretOptimal(X1, approx_empirique_T1, K, x0, M)\n",
    "\n",
    "X = np.array([x0*np.ones(M), X1, X2])\n",
    "\n",
    "X_tau = np.zeros(M)\n",
    "for m in range(M):\n",
    "    X_tau[m] = X[tau[m], m]\n",
    "\n",
    "echantillon = pos_part(K - X_tau)\n",
    "    \n",
    "mean_LongSchwartz = np.mean(echantillon)\n",
    "###################################################\n",
    " \n",
    "time6 = time()\n",
    " \n",
    "print(\"Prix Longstaff-Schwartz = %1.4f\" %mean_LongSchwartz)\n",
    "print(\"Time: %1.4f \\n\" %(time6 - time5 + time4 - time3 + timeSimulations))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
